"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1358],{1750:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>h,frontMatter:()=>c,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"connectors","title":"Connecting External Data Sources and Sinks","description":"Use CREATE TABLE statements to connect external data sources and sinks with your SQRL script using the WITH clause to provide connector configuration.","source":"@site/docs/connectors.md","sourceDirName":".","slug":"/connectors","permalink":"/docs/connectors","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\udcda SQRL Language","permalink":"/docs/sqrl-language"},"next":{"title":"\ud83d\udd17 Interface","permalink":"/docs/interface"}}');var r=s(4848),a=s(8453);const c={},i="Connecting External Data Sources and Sinks",o={},l=[{value:"Connector Management",id:"connector-management",level:2},{value:"LIKE Clause for Schema Loading",id:"like-clause-for-schema-loading",level:2},{value:"Inferring Schema from Data Files",id:"inferring-schema-from-data-files",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"connecting-external-data-sources-and-sinks",children:"Connecting External Data Sources and Sinks"})}),"\n",(0,r.jsxs)(n.p,{children:["Use ",(0,r.jsx)(n.code,{children:"CREATE TABLE"})," statements to connect external data sources and sinks with your SQRL script using the ",(0,r.jsx)(n.code,{children:"WITH"})," clause to provide connector configuration."]}),"\n",(0,r.jsx)(n.p,{children:"DataSQRL uses Apache Flink connectors and formats. To find a connector for your data system, use:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/connectors/table/overview/",children:"The Official Apache Flink connectors"})})," for Kafka, Filesystem, Kinesis, and many more."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"DataSQRL provided connectors"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://github.com/DataSQRL/flink-sql-runner?tab=readme-ov-file#dead-letter-queue-support-for-kafka-sources",children:"Safe Kafka Source Connectors"})})," which support dead-letter queues for faulty messages."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.a,{href:"https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/connectors/flink-sources/overview",children:"Apache Flink CDC connectors"})})," for Postgres, MySQL, Oracle, SqlServer, and other databases."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"connector-management",children:"Connector Management"}),"\n",(0,r.jsxs)(n.p,{children:["The best practice for managing connectors in your DataSQRL project is to place all ",(0,r.jsx)(n.code,{children:"CREATE TABLE"})," statements for one data source in a single ",(0,r.jsx)(n.code,{children:".sqrl"})," file inside the ",(0,r.jsx)(n.code,{children:"connectors"})," folder. This provides a modular structure for sources and sinks that supports reusability and replacing connectors for testing or different environments. ",(0,r.jsx)(n.a,{href:"sqrl-language#import-statement",children:"Import"})," those connector files into your main script."]}),"\n",(0,r.jsxs)(n.p,{children:["We ",(0,r.jsx)(n.strong,{children:"strongly encourage"})," the use of event-time processing and ensuring that all sources are configured with a proper watermark. While processing-time is supported, only event-time ensures consistent data processing and sane, reproducible results."]}),"\n",(0,r.jsxs)(n.p,{children:["When ingesting data from external data sources it is important to note the ",(0,r.jsx)(n.a,{href:"sqrl-language#type-system",children:"type of table"})," you are creating: an append-only ",(0,r.jsx)(n.code,{children:"STREAM"})," (e.g. with the ",(0,r.jsx)(n.code,{children:"filesystem"})," connector), ",(0,r.jsx)(n.code,{children:"VERSIONED_STATE"})," retraction stream (e.g. with the ",(0,r.jsx)(n.code,{children:"upsert-kafka"})," connector), or a ",(0,r.jsx)(n.code,{children:"LOOKUP"})," table (e.g. with the ",(0,r.jsx)(n.code,{children:"jdbc"})," connector). The table type determines what operations a table supports and how it should be processed."]}),"\n",(0,r.jsxs)(n.p,{children:["Specifically, entity data is often ingested as a stream of updates. To re-create the underlying entity ",(0,r.jsx)(n.code,{children:"VERSIONED_STATE"})," table, use the ",(0,r.jsx)(n.code,{children:"DISTINCT"})," statement with the entity's primary key."]}),"\n",(0,r.jsx)(n.h2,{id:"like-clause-for-schema-loading",children:"LIKE Clause for Schema Loading"}),"\n",(0,r.jsxs)(n.p,{children:["DataSQRL supports automatic schema loading from external schema files using the ",(0,r.jsx)(n.code,{children:"LIKE"})," clause. This feature eliminates the need to manually define column definitions when the schema already exists in a supported format."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE MyTable (\n  ...\n) WITH (\n  ...\n) LIKE 'mytable.avsc';\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"LIKE"})," clause:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automatically populates"})," column definitions from the referenced schema file"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maintains schema consistency"})," between your data pipeline and external systems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduces maintenance overhead"})," by eliminating manual schema translations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Supports relative paths"})," to schema files in your project structure"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"DataSQRL currently supports loading schemas from:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Avro schema files"})," (",(0,r.jsx)(n.code,{children:".avsc"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Assuming you have an Avro schema file ",(0,r.jsx)(n.code,{children:"user.avsc"})," for a Kafka topic:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE User (\n  last_updated TIMESTAMP_LTZ(3) NOT NULL METADATA FROM 'timestamp',\n  WATERMARK FOR last_updated AS last_updated - INTERVAL '1' SECOND\n) WITH (\n  'connector' = 'kafka',\n  ...\n) LIKE 'user.avsc';\n"})}),"\n",(0,r.jsx)(n.p,{children:"In this example:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.code,{children:"LIKE 'user.avsc'"})," clause loads all column definitions from the Avro schema"]}),"\n",(0,r.jsxs)(n.li,{children:["You add ",(0,r.jsx)(n.strong,{children:"metadata columns"})," (like ",(0,r.jsx)(n.code,{children:"last_updated"}),") and ",(0,r.jsx)(n.strong,{children:"watermark specifications"})]}),"\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.strong,{children:"connector configuration"})," remains in the ",(0,r.jsx)(n.code,{children:"WITH"})," clause as usual"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"inferring-schema-from-data-files",children:"Inferring Schema from Data Files"}),"\n",(0,r.jsxs)(n.p,{children:["To automatically discover the schema of a JSONL or CSV file, add the filename in the ",(0,r.jsx)(n.code,{children:"LIKE"})," clause.\nIn addition to generating the table columns based on the inferred schema of the data, this also configures the ",(0,r.jsx)(n.code,{children:"filesystem"})," connector to access the data."]}),"\n",(0,r.jsxs)(n.p,{children:["For example, suppose you have a ",(0,r.jsx)(n.code,{children:"users.jsonl"})," file in the ",(0,r.jsx)(n.code,{children:"connectors"})," directory, you can define the ",(0,r.jsx)(n.code,{children:"User"})," table simply as:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sql",children:"CREATE TABLE User (\n  WATERMARK FOR last_updated AS last_updated - INTERVAL '1' SECOND\n) WITH (\n  'source.monitor-interval' = '10 sec', -- remove for batch processing\n) LIKE 'users.jsonl';\n"})}),"\n",(0,r.jsx)(n.p,{children:"This syntax is useful when building DataSQRL projects from data files since it eliminates the manual schema creation."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>c,x:()=>i});var t=s(6540);const r={},a=t.createContext(r);function c(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:c(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);