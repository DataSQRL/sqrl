"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"\ud83d\udcd6 Overview","href":"/docs/intro/","docId":"intro/index","unlisted":false},{"type":"link","label":"\ud83d\ude80 Getting Started","href":"/docs/intro/getting-started","docId":"intro/getting-started","unlisted":false},{"type":"category","label":"\ud83e\uddf1 Core Concepts","collapsed":false,"items":[{"type":"link","label":"\ud83d\udcda SQRL Language","href":"/docs/sqrl-language","docId":"sqrl-language","unlisted":false},{"type":"link","label":"\ud83d\udd0c Source & Sink Connectors","href":"/docs/connectors","docId":"connectors","unlisted":false},{"type":"link","label":"\ud83d\udd17 Interface","href":"/docs/interface","docId":"interface","unlisted":false},{"type":"category","label":"\u2699\ufe0f Configuration","items":[{"type":"link","label":"Flink Engine","href":"/docs/configuration-engine/flink","docId":"configuration-engine/flink","unlisted":false},{"type":"link","label":"Kafka Engine","href":"/docs/configuration-engine/kafka","docId":"configuration-engine/kafka","unlisted":false},{"type":"link","label":"Vert.x Engine","href":"/docs/configuration-engine/vertx","docId":"configuration-engine/vertx","unlisted":false},{"type":"link","label":"PostgreSQL Engine","href":"/docs/configuration-engine/postgres","docId":"configuration-engine/postgres","unlisted":false},{"type":"link","label":"Iceberg Engine","href":"/docs/configuration-engine/iceberg","docId":"configuration-engine/iceberg","unlisted":false},{"type":"link","label":"DuckDB Engine","href":"/docs/configuration-engine/duckdb","docId":"configuration-engine/duckdb","unlisted":false},{"type":"link","label":"Snowflake Engine","href":"/docs/configuration-engine/snowflake","docId":"configuration-engine/snowflake","unlisted":false},{"type":"link","label":"Default Configuration","href":"/docs/configuration-default","docId":"configuration-default","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/configuration"},{"type":"category","label":"\ud83d\udd22 Functions","items":[{"type":"link","label":"System Functions","href":"/docs/functions-system-generated","docId":"functions-system-generated","unlisted":false},{"type":"link","label":"Library Functions","href":"/docs/functions-library-generated","docId":"functions-library-generated","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/functions"},{"type":"link","label":"\ud83d\udee0\ufe0f Compiler","href":"/docs/compiler","docId":"compiler","unlisted":false},{"type":"link","label":"\ud83e\udde0 Streaming Concepts","href":"/docs/intro/concepts","docId":"intro/concepts","unlisted":false}],"collapsible":true},{"type":"link","label":"\ud83c\udf93 Tutorials","href":"/docs/intro/tutorials","docId":"intro/tutorials","unlisted":false},{"type":"category","label":"\ud83d\udcd8 How To","items":[{"type":"link","label":"Project Structure","href":"/docs/howto/project-structure","docId":"howto/project-structure","unlisted":false},{"type":"link","label":"Enriching Data Streams","href":"/docs/howto/stream-enrichment","docId":"howto/stream-enrichment","unlisted":false},{"type":"link","label":"Subgraph Elimination","href":"/docs/howto/subgraph-elimination","docId":"howto/subgraph-elimination","unlisted":false},{"type":"link","label":"Templating","href":"/docs/howto/templating","docId":"howto/templating","unlisted":false},{"type":"link","label":"Testing Authorization","href":"/docs/howto/testing-authorization","docId":"howto/testing-authorization","unlisted":false},{"type":"link","label":"Testing","href":"/docs/howto/testing","docId":"howto/testing","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/docs/category/-how-to"},{"type":"category","label":"\ud83e\uddea Advanced","items":[{"type":"link","label":"\ud83d\udc69\u200d\ud83d\udcbb How DataSQRL Works","href":"/docs/deepdive","docId":"deepdive","unlisted":false},{"type":"link","label":"\ud83d\udd04 Compatibility","href":"/docs/compatibility","docId":"compatibility","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"compatibility":{"id":"compatibility","title":"Version Compatibility","description":"DataSQRL builds on top of Flink and the Flink connector ecosystem.","sidebar":"tutorialSidebar"},"compiler":{"id":"compiler","title":"DataSQRL Command","description":"The DataSQRL command compiles, runs, and tests SQRL scripts.","sidebar":"tutorialSidebar"},"configuration":{"id":"configuration","title":"DataSQRL Configuration (package.json file)","description":"DataSQRL projects are configured with one or more package.json files which are merged in the order they are provided to the DataSQRL command \u2013 latter files override fields in earlier ones, objects are deep-merged*, and array values are replaced wholesale. User provided configuration files are merged on top of the default package.json.","sidebar":"tutorialSidebar"},"configuration-default":{"id":"configuration-default","title":"Default DataSQRL package.json Configuration","description":"The following is the default configuration file that user provided configuration files are merged on top of. It provides the default values for all configuration options.","sidebar":"tutorialSidebar"},"configuration-engine/duckdb":{"id":"configuration-engine/duckdb","title":"DuckDB Engine Configuration","description":"DuckDB is a vectorized database query engine that excels at analytical queries and can read Iceberg tables efficiently.","sidebar":"tutorialSidebar"},"configuration-engine/flink":{"id":"configuration-engine/flink","title":"Flink Engine Configuration","description":"Apache Flink is a streaming and batch data processor that serves as the core data processing engine in DataSQRL pipelines.","sidebar":"tutorialSidebar"},"configuration-engine/iceberg":{"id":"configuration-engine/iceberg","title":"Iceberg Engine Configuration","description":"Apache Iceberg is an analytic database format that provides ACID transactions, schema evolution, and time travel capabilities for large analytic datasets.","sidebar":"tutorialSidebar"},"configuration-engine/kafka":{"id":"configuration-engine/kafka","title":"Kafka Engine Configuration","description":"Apache Kafka is a streaming data platform that serves as the log engine in DataSQRL pipelines for handling data streams and event logs.","sidebar":"tutorialSidebar"},"configuration-engine/postgres":{"id":"configuration-engine/postgres","title":"PostgreSQL Engine Configuration","description":"PostgreSQL is a realtime database that stores the materialized views and tables generated by your DataSQRL pipeline for low-latency querying.","sidebar":"tutorialSidebar"},"configuration-engine/snowflake":{"id":"configuration-engine/snowflake","title":"Snowflake Engine Configuration","description":"Snowflake is a cloud-based analytic database query engine that can read Iceberg tables and provide enterprise-scale analytical capabilities.","sidebar":"tutorialSidebar"},"configuration-engine/vertx":{"id":"configuration-engine/vertx","title":"Vert.x Engine Configuration","description":"Eclipse Vert.x is a reactive server framework that serves as the GraphQL API server, routing queries to the backing database/log engines.","sidebar":"tutorialSidebar"},"connectors":{"id":"connectors","title":"Connecting External Data Sources and Sinks","description":"Use CREATE TABLE statements to connect external data sources and sinks with your SQRL script using the WITH clause to provide connector configuration.","sidebar":"tutorialSidebar"},"deepdive":{"id":"deepdive","title":"Deep Dive: How DataSQRL Works","description":"The DataSQRL compile executes the following steps:","sidebar":"tutorialSidebar"},"functions":{"id":"functions","title":"Functions","description":"System Functions","sidebar":"tutorialSidebar"},"functions-library-generated":{"id":"functions-library-generated","title":"Library Functions","description":"DataSQRL provides extended library functions that can be imported into your SQRL scripts. These functions offer specialized capabilities for mathematical operations, data processing, AI integration, and external system connectivity.","sidebar":"tutorialSidebar"},"functions-system-generated":{"id":"functions-system-generated","title":"System Functions","description":"DataSQRL provides built-in system functions that are available in all SQRL scripts. These functions are grouped by functionality and provide essential operations for data processing, JSON manipulation, vector operations, and text processing.","sidebar":"tutorialSidebar"},"howto/project-structure":{"id":"howto/project-structure","title":"Project Structure","description":"A DataSQRL project is structured as follows where  is the project name.","sidebar":"tutorialSidebar"},"howto/stream-enrichment":{"id":"howto/stream-enrichment","title":"Enriching Data Streams","description":"A common requirement in stream processing is to enrich a STREAM of events with dimensional data in a time-consistent manner.","sidebar":"tutorialSidebar"},"howto/subgraph-elimination":{"id":"howto/subgraph-elimination","title":"Subgraph Elimination","description":"Sometimes the Flink optimizer is too smart for its own good and will push down predicates that make common subgraph identification impossible resulting in duplicate computation.","sidebar":"tutorialSidebar"},"howto/templating":{"id":"howto/templating","title":"Templating","description":"DataSQRL uses the Mustache templating engine to substitute configuration variables in SQRL scripts, making them reusable and configurable without modifying the code.","sidebar":"tutorialSidebar"},"howto/testing":{"id":"howto/testing","title":"Testing","description":"DataSQRL\'s automated test runner can execute two types of snapshot test via the run command:","sidebar":"tutorialSidebar"},"howto/testing-authorization":{"id":"howto/testing-authorization","title":"Testing Authorization","description":"You can test record filtering, data masking, and other types of authorization based data access control with DataSQRL\'s automated test runner via the test command.","sidebar":"tutorialSidebar"},"interface":{"id":"interface","title":"Designing the Interface","description":"Based on the SQRL script, DataSQRL generates the interface for the compiled data pipeline. DataSQRL supports the following interfaces:","sidebar":"tutorialSidebar"},"intro/concepts":{"id":"intro/concepts","title":"Key DataSQRL Concepts","description":"This document explains some of the key concepts in streaming data processing.","sidebar":"tutorialSidebar"},"intro/getting-started":{"id":"intro/getting-started","title":"Getting Started with DataSQRL","description":"Welcome to DataSQRL! This guide walks you through building and running your first data pipeline using SQRL \u2014 from setup to customization and debugging.","sidebar":"tutorialSidebar"},"intro/index":{"id":"intro/index","title":"DataSQRL Documentation","description":"DataSQRL is a framework for building data pipelines with guaranteed data integrity. It compiles SQL scripts into fully integrated data infrastructure that ingests data from multiple sources, transforms it through stream processing, and serves the results as realtime data APIs, LLM tooling, or Apache Iceberg views.","sidebar":"tutorialSidebar"},"intro/tutorials":{"id":"intro/tutorials","title":"DataSQRL Tutorials","description":"The tutorials are implemented in the DataSQRL Examples repository.","sidebar":"tutorialSidebar"},"sqrl-language":{"id":"sqrl-language","title":"SQRL Language Specification","description":"SQRL is an extension of FlinkSQL that adds support for table functions and convenience syntax to build reactive data processing and serving applications.","sidebar":"tutorialSidebar"},"stdlib-docs/CLAUDE":{"id":"stdlib-docs/CLAUDE","title":"CLAUDE.md","description":"This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository."},"stdlib-docs/README":{"id":"stdlib-docs/README","title":"README","description":"Deploy jars"},"stdlib-docs/RELEASE":{"id":"stdlib-docs/RELEASE","title":"Release Process for flink-sql-runner","description":"Releasing a new version of flink-sql-runner is simple and fully automated via GitHub Actions."}}}}')}}]);