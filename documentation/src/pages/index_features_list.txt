
* Full Control (Hints)

* Local Developer Workflow (video)

May want to include:
* Rich Function Library and Custom Functions
* Automatic Database Indexing: Smart index selection for database tables including vector indexes for embeddings
* Automatic API Generation: with customization
* Structured and Unstructured Data
* Realtime, Mini-Batch, and Batch
* Multi-Engine Architecture - Integrates Apache Flink, PostgreSQL, Kafka, GraphQL APIs into coherent data stacks, PostgreSQL, DuckDB, Snowflake, Yugabyte, Iceberg with native optimizations
* Observable: Metrics and UI's across engines
* GraphQL Subscriptions

Included:
* Connectors (stream, cdc, lakehouse): Support for Kafka, Kinesis, filesystem, PostgreSQL, Iceberg, and more via Flink connectors
* Run Anywhere (Docker, K8s, cloud)
* AI-native: Built-in support for vector embeddings, LLM invocation, and ML model inference
* Data Lineage
* Local Developer Workflow (video): quick iteration
* JWT Authorization
* Fault Tolerant and Scalable
* DevOps: CI/CD, quick iteration, regression testing, performance testing
* Optimized DAG Planning - Intelligent query optimization and execution plan generation across multiple engines, Built-in cost model for optimal resource allocation and performance
* Automated Code Generation - Compiler automatically generates glue code, schemas, mappings, and deployment artifacts
* Proven Open-Source (get artifacts)
* Testing Framework: Built-in test execution with snapshot testing and automated regression detection
* Guaranteed Consistency: Exactly-once processing and consistent data across pipeline steps.
* SQL is All you need: Use familiar SQL syntax instead of complex code for building complete data pipelines, low learning curve, quick results.
* SQL is All you need: Complex Transformations, Time-based Processing: windows, temporal joins
* REST API
* Semantic Annotations for MCP




