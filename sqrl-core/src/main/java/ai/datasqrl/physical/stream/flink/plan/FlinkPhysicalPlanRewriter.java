package ai.datasqrl.physical.stream.flink.plan;

import lombok.AllArgsConstructor;
import org.apache.calcite.plan.Convention;
import org.apache.calcite.plan.RelOptCluster;
import org.apache.calcite.plan.RelTraitSet;
import org.apache.calcite.rel.RelNode;
import org.apache.calcite.rel.RelShuttleImpl;
import org.apache.calcite.rel.core.CorrelationId;
import org.apache.calcite.rel.core.TableFunctionScan;
import org.apache.calcite.rel.core.TableScan;
import org.apache.calcite.rel.core.Uncollect;
import org.apache.calcite.rel.logical.*;
import org.apache.calcite.rel.type.RelDataTypeField;
import org.apache.flink.calcite.shaded.com.google.common.collect.ImmutableList;
import org.apache.flink.calcite.shaded.com.google.common.collect.ImmutableSet;
import org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl;
import org.apache.flink.table.planner.calcite.FlinkRelBuilder;
import org.apache.flink.table.planner.operations.PlannerQueryOperation;
import org.apache.flink.table.planner.plan.nodes.calcite.LogicalWatermarkAssigner;
import org.apache.flink.table.planner.plan.trait.FlinkRelDistribution;
import org.apache.flink.table.planner.plan.trait.MiniBatchIntervalTrait;
import org.apache.flink.table.planner.plan.trait.ModifyKindSetTrait;
import org.apache.flink.table.planner.plan.trait.UpdateKindTrait;

import java.util.List;
import java.util.stream.Collectors;

/**
 * Rewrites the streaming physical plan generated by the optimizer for Flink.
 * Specifically, this means:
 *  - Injecting a Flink Calcite cluster to replace the SQRL calcite cluster
 *  - Adding watermarks and propagating timestamp columns
 *  - Expanding temporal joins
 *  - Expanding time-based aggregations into Flink window aggregations
 *  - Handling interval joins
 */
@AllArgsConstructor
public class FlinkPhysicalPlanRewriter extends RelShuttleImpl {
  StreamTableEnvironmentImpl tEnv;
  RelOptCluster cluster;
  RelTraitSet defaultTrait;

  public static RelNode rewrite(StreamTableEnvironmentImpl tEnv, RelOptCluster cluster, RelNode input) {
    RelTraitSet defaultTraits = RelTraitSet.createEmpty().plus(Convention.NONE)
        .plus(FlinkRelDistribution.ANY())
        .plus(MiniBatchIntervalTrait.NONE())
        .plus(ModifyKindSetTrait.EMPTY())
        .plus(UpdateKindTrait.NONE());

    return input.accept(new FlinkPhysicalPlanRewriter(tEnv, cluster, defaultTraits));
  }

  private FlinkRelBuilder getBuilder() {
    return FlinkRelBuilder.of(cluster,null);
  }

  @Override
  public RelNode visit(TableScan scan) {
    //Lookup TableSourceTable in flink, add statistics over
    PlannerQueryOperation op = (PlannerQueryOperation) tEnv.getParser().parse("select * from "
            + scan.getTable().getQualifiedName().get(scan.getTable().getQualifiedName().size() - 1))
        .get(0);

    return op.getCalciteTree().getInput(0);
  }

  @Override
  public RelNode visit(TableFunctionScan scan) {
    List<RelNode> inputs = scan.getInputs().stream()
        .map(this::visit)
        .collect(Collectors.toList());
    return new LogicalTableFunctionScan(cluster, defaultTrait, inputs, scan.getCall(),
        scan.getElementType(), scan.getRowType(), scan.getColumnMappings());
  }

  @Override
  public RelNode visit(LogicalValues values) {
    return new LogicalValues(cluster, defaultTrait, values.getRowType(), values.tuples);
  }

  @Override
  public RelNode visit(LogicalCorrelate correlate) {
    return new LogicalCorrelate(cluster,
        defaultTrait, correlate.getLeft().accept(this), correlate.getRight().accept(this),
        correlate.getCorrelationId(), correlate.getRequiredColumns(), correlate.getJoinType());
  }

  @Override
  public RelNode visit(LogicalProject project) {
    return new LogicalProject(cluster, defaultTrait, project.getHints(),
        project.getInput().accept(this),
        project.getProjects(), project.getRowType());
  }

  @Override
  public RelNode visit(LogicalAggregate aggregate) {
    return new LogicalAggregate(cluster, defaultTrait, aggregate.getHints(),
        aggregate.getInput().accept(this),
        aggregate.getGroupSet(),
        aggregate.getGroupSets(), aggregate.getAggCallList());
  }

  @Override
  public RelNode visit(LogicalFilter filter) {
    return new LogicalFilter(cluster, defaultTrait, filter.getInput().accept(this),
        filter.getCondition(),
        (ImmutableSet<CorrelationId>) filter.getVariablesSet());
  }

  @Override
  public RelNode visit(LogicalJoin join) {
    return new LogicalJoin(cluster,
        defaultTrait, join.getHints(), join.getLeft().accept(this), join.getRight().accept(this),
        join.getCondition(), join.getVariablesSet(), join.getJoinType(), join.isSemiJoinDone(),
        (ImmutableList<RelDataTypeField>) join.getSystemFieldList());
  }

  @Override
  public RelNode visit(LogicalUnion union) {
    return super.visit(union);
  }

  @Override
  public RelNode visit(LogicalIntersect intersect) {
    return super.visit(intersect);
  }

  @Override
  public RelNode visit(LogicalMinus minus) {
    return super.visit(minus);
  }

  @Override
  public RelNode visit(LogicalSort sort) {
    return sort.getInput().accept(this); //just remove sort atm
//    throw new RuntimeException("sort todo");
  }

  @Override
  public RelNode visit(RelNode other) {
    if (other instanceof Uncollect) {
      Uncollect uncollect = (Uncollect) other;
      return new Uncollect(cluster, defaultTrait, uncollect.getInput().accept(this),
          uncollect.withOrdinality, List.of());
    } else if (other instanceof LogicalWatermarkAssigner) {
      LogicalWatermarkAssigner watermarkAssigner = (LogicalWatermarkAssigner) other;
      return new LogicalWatermarkAssigner(cluster, defaultTrait,
          watermarkAssigner.getInput().accept(this),
          watermarkAssigner.rowtimeFieldIndex(), watermarkAssigner.watermarkExpr());
    }
    throw new RuntimeException("not yet implemented:" + other.getClass());
  }
}
