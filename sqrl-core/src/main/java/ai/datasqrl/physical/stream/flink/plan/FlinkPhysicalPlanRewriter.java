package ai.datasqrl.physical.stream.flink.plan;

import ai.datasqrl.plan.calcite.hints.SqrlHint;
import ai.datasqrl.plan.calcite.hints.WatermarkHint;
import ai.datasqrl.plan.calcite.table.ImportedSourceTable;
import com.google.common.base.Preconditions;
import lombok.AllArgsConstructor;
import org.apache.calcite.rel.RelNode;
import org.apache.calcite.rel.RelShuttleImpl;
import org.apache.calcite.rel.core.JoinRelType;
import org.apache.calcite.rel.core.TableFunctionScan;
import org.apache.calcite.rel.core.TableScan;
import org.apache.calcite.rel.core.Uncollect;
import org.apache.calcite.rel.logical.*;
import org.apache.calcite.rel.type.RelDataType;
import org.apache.calcite.rel.type.RelDataTypeField;
import org.apache.calcite.rex.RexInputRef;
import org.apache.calcite.rex.RexNode;
import org.apache.calcite.rex.RexShuttle;
import org.apache.calcite.tools.RelBuilder;
import org.apache.flink.table.api.bridge.java.internal.StreamTableEnvironmentImpl;
import org.apache.flink.table.planner.calcite.FlinkRelBuilder;
import org.apache.flink.table.planner.calcite.FlinkRexBuilder;
import org.apache.flink.table.planner.delegation.StreamPlanner;

import java.util.ArrayList;
import java.util.List;
import java.util.function.Supplier;
import java.util.stream.Collectors;

/**
 * Rewrites the streaming physical plan generated by the optimizer for Flink.
 * Specifically, this means:
 *  - Injecting a Flink Calcite cluster to replace the SQRL calcite cluster
 *  - Adding watermarks and propagating timestamp columns
 *  - Expanding temporal joins
 *  - Expanding time-based aggregations into Flink window aggregations
 *  - Handling interval joins
 */
@AllArgsConstructor
public class FlinkPhysicalPlanRewriter extends RelShuttleImpl {
  StreamTableEnvironmentImpl tEnv;
  Supplier<FlinkRelBuilder> relBuilderFactory;

  public static RelNode rewrite(StreamTableEnvironmentImpl tEnv, RelNode input) {
    return input.accept(new FlinkPhysicalPlanRewriter(tEnv, () -> ((StreamPlanner) tEnv.getPlanner()).getRelBuilder()));
  }

  private FlinkRelBuilder getBuilder() {
    return relBuilderFactory.get();
  }

  @Override
  public RelNode visit(TableScan scan) {
    ImportedSourceTable t = scan.getTable().unwrap(ImportedSourceTable.class);
    String tableName = t.getNameId();
    FlinkRelBuilder relBuilder = getBuilder();
    relBuilder.scan(tableName);
    SqrlHint.fromRel(scan, WatermarkHint.CONSTRUCTOR).ifPresent(watermark -> addWatermark(relBuilder,watermark.getTimestampIdx()));
    return relBuilder.build();
  }

  @Override
  public RelNode visit(LogicalProject project) {
    FlinkRelBuilder relBuilder = getBuilder();
    relBuilder.push(project.getInput().accept(this));
    relBuilder.project(project.getProjects().stream().map(rex -> rewrite(rex,relBuilder)).collect(Collectors.toList()),
            project.getRowType().getFieldList().stream().map(f -> f.getName()).collect(Collectors.toList()));
    SqrlHint.fromRel(project, WatermarkHint.CONSTRUCTOR).ifPresent(watermark -> addWatermark(relBuilder,watermark.getTimestampIdx()));
    return relBuilder.build();
  }

  private void addWatermark(FlinkRelBuilder relBuilder, int timestampIndex) {
    relBuilder.watermark(timestampIndex,getRexBuilder(relBuilder).makeInputRef(relBuilder.peek(), timestampIndex));
  }

  @Override
  public RelNode visit(LogicalFilter filter) {
    FlinkRelBuilder relBuilder = getBuilder();
    relBuilder.push(filter.getInput().accept(this));
    relBuilder.filter(filter.getVariablesSet(),rewrite(filter.getCondition(),relBuilder));
    return relBuilder.build();
  }

  @Override
  public RelNode visit(LogicalJoin join) {
    FlinkRelBuilder relBuilder = getBuilder();
    RelNode left = join.getLeft().accept(this), right = join.getRight().accept(this);
    relBuilder.push(left);
    relBuilder.push(right);
    JoinRelType joinType = join.getJoinType();
    if (joinType==JoinRelType.INTERVAL) {
      //Any other validation we need to do here?
      joinType = JoinRelType.INNER;
    }
    relBuilder.join(joinType,rewrite(join.getCondition(), relBuilder, left, right));
    return relBuilder.build();
  }

  @Override
  public RelNode visit(LogicalAggregate aggregate) {
    throw new UnsupportedOperationException("Not yet implemented");
//    return new LogicalAggregate(cluster, defaultTrait, aggregate.getHints(),
//        aggregate.getInput().accept(this),
//        aggregate.getGroupSet(),
//        aggregate.getGroupSets(), aggregate.getAggCallList());
  }

  @Override
  public RelNode visit(LogicalValues values) {
    return getBuilder().values(values.tuples, values.getRowType()).build();
  }

  @Override
  public RelNode visit(LogicalUnion union) {
    return super.visit(union);
  }

  @Override
  public RelNode visit(LogicalIntersect intersect) {
    return super.visit(intersect);
  }

  @Override
  public RelNode visit(LogicalMinus minus) {
    return super.visit(minus);
  }

  @Override
  public RelNode visit(LogicalSort sort) {
    return sort.getInput().accept(this); //just remove sort atm
//    throw new RuntimeException("sort todo");
  }

  @Override
  public RelNode visit(TableFunctionScan scan) {
    throw new UnsupportedOperationException("Not yet supported");
//    List<RelNode> inputs = scan.getInputs().stream()
//        .map(this::visit)
//        .collect(Collectors.toList());
//    return new LogicalTableFunctionScan(cluster, defaultTrait, inputs, scan.getCall(),
//        scan.getElementType(), scan.getRowType(), scan.getColumnMappings());
  }

  @Override
  public RelNode visit(LogicalCorrelate correlate) {
    FlinkRelBuilder relBuilder = getBuilder();
    relBuilder.push(correlate.getLeft().accept(this));
    RelDataType base = relBuilder.peek().getRowType();
    relBuilder.push(correlate.getRight().accept(this));
    relBuilder.correlate(correlate.getJoinType(), correlate.getCorrelationId(),
            correlate.getRequiredColumns().asList().stream().map(i -> relBuilder.getRexBuilder().makeInputRef(base,i)).collect(Collectors.toList()));
    return relBuilder.build();
  }

  @Override
  public RelNode visit(RelNode other) {
    if (other instanceof Uncollect) {
      Uncollect uncollect = (Uncollect) other;
      RelBuilder relBuilder = getBuilder();
      relBuilder.push(uncollect.getInput().accept(this));
      relBuilder.uncollect(List.of(),uncollect.withOrdinality);
      return relBuilder.build();
    } /* else if (other instanceof LogicalWatermarkAssigner) {
      LogicalWatermarkAssigner watermarkAssigner = (LogicalWatermarkAssigner) other;
      return new LogicalWatermarkAssigner(cluster, defaultTrait,
          watermarkAssigner.getInput().accept(this),
          watermarkAssigner.rowtimeFieldIndex(), watermarkAssigner.watermarkExpr());
    } */
    throw new RuntimeException("not yet implemented:" + other.getClass());
  }


  /*
  ====== Rewriting RexNodes
   */

  private static FlinkRexBuilder getRexBuilder(FlinkRelBuilder relBuilder) {
    return new FlinkRexBuilder(relBuilder.getTypeFactory());
  }

  private RexNode rewrite(RexNode node, FlinkRelBuilder relBuilder) {
    return rewrite(node, relBuilder, relBuilder.peek());
  }

  private RexNode rewrite(RexNode node, FlinkRelBuilder relBuilder, RelNode... inputNodes) {
    Preconditions.checkArgument(inputNodes!=null && inputNodes.length>0);
    List<RelDataTypeField> fields;
    if (inputNodes.length==1) {
      fields = inputNodes[0].getRowType().getFieldList();
    } else {
      fields = new ArrayList<>();
      for (RelNode input : inputNodes) {
        fields.addAll(input.getRowType().getFieldList());
      }
    }
    return node.accept(new RexRewriter(fields,
            FlinkPhysicalPlanRewriter.getRexBuilder(relBuilder)));
  }

  @AllArgsConstructor
  private static class RexRewriter extends RexShuttle {

    private final List<RelDataTypeField> inputFields;
    private final FlinkRexBuilder rexBuilder;

    @Override
    public RexNode visitInputRef(RexInputRef ref) {
      return rexBuilder.makeInputRef(inputFields.get(ref.getIndex()).getType(),ref.getIndex());
    }
  }

}
