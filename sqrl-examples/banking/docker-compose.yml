# This is a docker-compose template for starting a DataSQRL compiled data pipeline
# This template uses the Apache Flink as the stream engine, Postgres as the database engine, and Vertx as the server engine.
# It assumes that:
# 1. You ran the `compile` command to compile your SQRL script (and API specification)
# 2. Are in the `build/deploy` directory which contains the deployment artifacts generated by the compiler
# 3. Have built the deployment artifacts for each pipeline engine
# Refer to the deployment documentation for more information:
# https://www.datasqrl.com/docs/reference/operations/deploy/overview/
version: "3.8"
services:
  database:
    image: postgres:14.6-alpine
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=datasqrl
    ports:
      - '5432:5432'
    volumes:
      - ./database-schema.sql:/docker-entrypoint-initdb.d/init-schema.sql

  flink-jobmanager:
    image: flink:1.16.1-scala_2.12-java11
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    volumes:
      - /Users/matthias/git/sqml/sqrl-examples/banking:/Users/matthias/git/sqml/sqrl-examples/banking

  flink-taskmanager:
    image: flink:1.16.1-scala_2.12-java11
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 1
    volumes:
      - /Users/matthias/git/sqml/sqrl-examples/banking:/Users/matthias/git/sqml/sqrl-examples/banking

  kafka:
    image: docker.io/bitnami/kafka:3.4
    ports:
      - "9092:9092"
    volumes:
      - "kafka_data:/bitnami"
    environment:
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - ALLOW_PLAINTEXT_LISTENER=yes
  kafka-setup:
    image: docker.io/bitnami/kafka:3.4
    volumes:
      - './create-topics.sh:/create-topics.sh'
    command: ['/bin/bash', '/create-topics.sh']
    depends_on:
      - kafka

  server:
    image: eclipse-temurin:11
    command: java -jar vertx-server.jar
    depends_on:
      - database
      - kafka-setup
    ports:
      - "8888:8888"
    volumes:
      - ./server-model.json:/model.json
      - ./server-config.json:/config.json
      - ./vertx-server.jar:/vertx-server.jar

  flink-job-submitter:
    image: badouralix/curl-jq:alpine
    depends_on:
      - flink-jobmanager
      - database
      - kafka-setup
    volumes:
      - ./flink-job.jar:/flink-job.jar
    entrypoint: /bin/sh -c
    command: >
      "while ! curl -s http://flink-jobmanager:8081/overview | grep -q '\"taskmanagers\":1'; do
        echo 'Waiting for Flink JobManager REST API...';
        sleep 5;
      done;
      echo 'Submitting Flink job...';
      upload_response=$(curl -X POST -H "Expect:" -F "jarfile=@flink-job.jar" http://flink-jobmanager:8081/jars/upload);
      echo $$upload_response;
      echo \"$$upload_response\";
      jar_id=$(echo $$upload_response | jq -r '.filename');
      echo $$jar_id;
      echo \"$$jar_id\";
      filename=$(echo $$jar_id | awk -F'/' '{print $$NF}');
      sleep 3;
      echo $$filename
      echo \"curl -X POST \"http://flink-jobmanager:8081/jars/$${filename}/run\";\";
      post_response=$(curl -X POST \"http://flink-jobmanager:8081/jars/$${filename}/run\");
      echo $$post_response;
      echo 'Job submitted.'"

volumes:
  database:
    driver: local
  kafka_data:
    driver: local
