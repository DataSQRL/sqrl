>>>inferred_schema.graphqls
"An RFC-3339 compliant Full Date Scalar"
scalar Date

"A DateTime scalar that handles both full RFC3339 and shorter timestamp formats"
scalar DateTime

"A JSON scalar"
scalar JSON

"24-hour clock time value string in the format `hh:mm:ss` or `hh:mm:ss.sss`."
scalar LocalTime

"A 64-bit signed integer"
scalar Long

type MyTable1 {
  id: Long!
  hello: String!
}

type MyTable2 {
  id: Long!
  hello: String!
}

type MyTable3 {
  id: Long!
  hello: String!
}

type Query {
  MyTable1(limit: Int = 10, offset: Int = 0): [MyTable1!]
  MyTable2(limit: Int = 10, offset: Int = 0): [MyTable2!]
  MyTable3(limit: Int = 10, offset: Int = 0): [MyTable3!]
}

enum _McpMethodType {
  NONE
  TOOL
  RESOURCE
}

enum _RestMethodType {
  NONE
  GET
  POST
}

directive @api(mcp: _McpMethodType, rest: _RestMethodType, uri: String) on QUERY | MUTATION | FIELD_DEFINITION

>>>pipeline_explain.txt
=== MyTable1
ID:          default_catalog.default_database.MyTable1
Type:        stream
Stage:       iceberg
Primary key: -
Timestamp:   -
---
Schema:
 - id: BIGINT NOT NULL
 - hello: CHAR(12) CHARACTER SET "UTF-16LE" NOT NULL
Inputs:
 - default_catalog.default_database._MyApplications1
Annotations:
 - stream-root: _Applications

=== MyTable2
ID:          default_catalog.default_database.MyTable2
Type:        stream
Stage:       iceberg
Primary key: -
Timestamp:   -
---
Schema:
 - id: BIGINT NOT NULL
 - hello: CHAR(12) CHARACTER SET "UTF-16LE" NOT NULL
Inputs:
 - default_catalog.default_database._MyApplications2
Annotations:
 - stream-root: _Applications

=== MyTable3
ID:          default_catalog.default_database.MyTable3
Type:        stream
Stage:       postgres
Primary key: -
Timestamp:   -
---
Schema:
 - id: BIGINT NOT NULL
 - hello: CHAR(12) CHARACTER SET "UTF-16LE" NOT NULL
Inputs:
 - default_catalog.default_database._MyApplications2
Annotations:
 - stream-root: _Applications

=== _Applications
ID:          default_catalog.default_database._Applications
Type:        stream
Stage:       flink
Primary key: id, updated_at
Timestamp:   updated_at
---
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Inputs:
 - default_catalog.default_database._Applications__base
Annotations:
 - stream-root: _Applications

=== _MyApplications1
ID:          default_catalog.default_database._MyApplications1
Type:        stream
Stage:       flink
Primary key: id, updated_at
Timestamp:   updated_at
---
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Inputs:
 - default_catalog.default_database._Applications
Annotations:
 - stream-root: _Applications

=== _MyApplications2
ID:          default_catalog.default_database._MyApplications2
Type:        stream
Stage:       flink
Primary key: id, updated_at
Timestamp:   updated_at
---
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Inputs:
 - default_catalog.default_database._Applications
Annotations:
 - stream-root: _Applications

>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `_Applications__schema` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
)
WITH (
  'connector' = 'filesystem',
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/applications.jsonl'
);
CREATE TABLE `_Applications` (
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED,
  WATERMARK FOR `updated_at` AS `updated_at` - INTERVAL '0.001' SECOND
)
WITH (
  'source.monitor-interval' = '1'
)
LIKE `_Applications__schema`;
CREATE VIEW `_MyApplications1`
AS
SELECT *
FROM `_Applications`;
CREATE VIEW `_MyApplications2`
AS
SELECT *
FROM `_Applications`
WHERE `id` >= 0;
CREATE VIEW `MyTable1`
AS
SELECT `id`, 'hello world1' AS `hello`
FROM `_MyApplications1`;
CREATE VIEW `MyTable2`
AS
SELECT `id`, 'hello world2' AS `hello`
FROM `_MyApplications2`;
CREATE VIEW `MyTable3`
AS
SELECT `id`, 'hello world3' AS `hello`
FROM `_MyApplications2`;
CREATE TABLE `_MyApplications1_1` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED
)
PARTITIONED BY (`id`)
WITH (
  'catalog-name' = 'mydatabase',
  'catalog-table' = '_MyApplications1',
  'catalog-type' = 'hadoop',
  'connector' = 'iceberg',
  'warehouse' = '/tmp/duckdb-with-cache',
  'write.parquet.page-size-bytes' = '1000'
);
CREATE TABLE `_MyApplications2_2` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED
)
WITH (
  'catalog-name' = 'mydatabase',
  'catalog-table' = '_MyApplications2',
  'catalog-type' = 'hadoop',
  'connector' = 'iceberg',
  'warehouse' = '/tmp/duckdb-with-cache',
  'write.parquet.page-size-bytes' = '1000'
);
CREATE TABLE `_MyApplications2_3` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED
)
WITH (
  'connector' = 'jdbc-sqrl',
  'driver' = 'org.postgresql.Driver',
  'password' = '${POSTGRES_PASSWORD}',
  'table-name' = '_MyApplications2',
  'url' = 'jdbc:postgresql://${POSTGRES_AUTHORITY}',
  'username' = '${POSTGRES_USERNAME}'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`_MyApplications1_1`
SELECT *
 FROM `default_catalog`.`default_database`.`_MyApplications1`
;
INSERT INTO `default_catalog`.`default_database`.`_MyApplications2_2`
 SELECT *
  FROM `default_catalog`.`default_database`.`_MyApplications2`
 ;
 INSERT INTO `default_catalog`.`default_database`.`_MyApplications2_3`
  SELECT *
   FROM `default_catalog`.`default_database`.`_MyApplications2`
  ;
  END
>>>iceberg-duckdb-schema.sql
CREATE TABLE IF NOT EXISTS "_MyApplications1" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL, "updated_at" TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL, PRIMARY KEY ("id","updated_at"));
CREATE TABLE IF NOT EXISTS "_MyApplications2" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL, "updated_at" TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL, PRIMARY KEY ("id","updated_at"))
>>>iceberg-duckdb-views.sql
CREATE OR REPLACE VIEW "MyTable1"("id", "hello") AS SELECT "id", 'hello world1' AS "hello"
FROM "iceberg_scan"('/tmp/duckdb-with-cache/default_database/_MyApplications1', ALLOW_MOVED_PATHS = TRUE);
CREATE OR REPLACE VIEW "MyTable2"("id", "hello") AS SELECT "id", 'hello world2' AS "hello"
FROM "iceberg_scan"('/tmp/duckdb-with-cache/default_database/_MyApplications2', ALLOW_MOVED_PATHS = TRUE)
>>>iceberg-schema.sql
CREATE TABLE IF NOT EXISTS "_MyApplications1" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL, PRIMARY KEY ("id","updated_at")) PARTITIONED BY ("id");
CREATE TABLE IF NOT EXISTS "_MyApplications2" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL, PRIMARY KEY ("id","updated_at"))
>>>iceberg-views.sql

>>>kafka.json
{
  "topics" : [ ],
  "testRunnerTopics" : [ ]
}
>>>postgres-schema.sql
CREATE TABLE IF NOT EXISTS "_MyApplications2" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL, PRIMARY KEY ("id","updated_at"));

CREATE INDEX IF NOT EXISTS "_MyApplications2_hash_c0" ON "_MyApplications2" USING hash ("id")
>>>postgres-views.sql
CREATE OR REPLACE VIEW "MyTable3"("id", "hello") AS SELECT "id", 'hello world3' AS "hello"
FROM "_MyApplications2"
>>>vertx.json
{
  "models" : {
    "v1" : {
      "queries" : [
        {
          "type" : "args",
          "parentType" : "Query",
          "fieldName" : "MyTable1",
          "exec" : {
            "arguments" : [
              {
                "type" : "variable",
                "path" : "limit"
              },
              {
                "type" : "variable",
                "path" : "offset"
              }
            ],
            "query" : {
              "type" : "SqlQuery",
              "sql" : "SELECT \"id\", 'hello world1' AS \"hello\"\nFROM \"iceberg_scan\"('/tmp/duckdb-with-cache/default_database/_MyApplications1', ALLOW_MOVED_PATHS = TRUE)",
              "parameters" : [ ],
              "pagination" : "LIMIT_AND_OFFSET",
              "cacheDurationMs" : 0,
              "database" : "DUCKDB"
            }
          }
        },
        {
          "type" : "args",
          "parentType" : "Query",
          "fieldName" : "MyTable2",
          "exec" : {
            "arguments" : [
              {
                "type" : "variable",
                "path" : "limit"
              },
              {
                "type" : "variable",
                "path" : "offset"
              }
            ],
            "query" : {
              "type" : "SqlQuery",
              "sql" : "SELECT \"id\", 'hello world2' AS \"hello\"\nFROM \"iceberg_scan\"('/tmp/duckdb-with-cache/default_database/_MyApplications2', ALLOW_MOVED_PATHS = TRUE)",
              "parameters" : [ ],
              "pagination" : "LIMIT_AND_OFFSET",
              "cacheDurationMs" : 0,
              "database" : "DUCKDB"
            }
          }
        },
        {
          "type" : "args",
          "parentType" : "Query",
          "fieldName" : "MyTable3",
          "exec" : {
            "arguments" : [
              {
                "type" : "variable",
                "path" : "limit"
              },
              {
                "type" : "variable",
                "path" : "offset"
              }
            ],
            "query" : {
              "type" : "SqlQuery",
              "sql" : "SELECT \"id\", 'hello world3' AS \"hello\"\nFROM \"_MyApplications2\"",
              "parameters" : [ ],
              "pagination" : "LIMIT_AND_OFFSET",
              "cacheDurationMs" : 0,
              "database" : "POSTGRES"
            }
          }
        }
      ],
      "mutations" : [ ],
      "subscriptions" : [ ],
      "operations" : [
        {
          "function" : {
            "name" : "GetMyTable1",
            "parameters" : {
              "type" : "object",
              "properties" : {
                "offset" : {
                  "type" : "integer"
                },
                "limit" : {
                  "type" : "integer"
                }
              },
              "required" : [ ]
            }
          },
          "format" : "JSON",
          "apiQuery" : {
            "query" : "query MyTable1($limit: Int = 10, $offset: Int = 0) {\nMyTable1(limit: $limit, offset: $offset) {\nid\nhello\n}\n\n}",
            "queryName" : "MyTable1",
            "operationType" : "QUERY"
          },
          "mcpMethod" : "TOOL",
          "restMethod" : "GET",
          "uriTemplate" : "queries/MyTable1{?offset,limit}"
        },
        {
          "function" : {
            "name" : "GetMyTable2",
            "parameters" : {
              "type" : "object",
              "properties" : {
                "offset" : {
                  "type" : "integer"
                },
                "limit" : {
                  "type" : "integer"
                }
              },
              "required" : [ ]
            }
          },
          "format" : "JSON",
          "apiQuery" : {
            "query" : "query MyTable2($limit: Int = 10, $offset: Int = 0) {\nMyTable2(limit: $limit, offset: $offset) {\nid\nhello\n}\n\n}",
            "queryName" : "MyTable2",
            "operationType" : "QUERY"
          },
          "mcpMethod" : "TOOL",
          "restMethod" : "GET",
          "uriTemplate" : "queries/MyTable2{?offset,limit}"
        },
        {
          "function" : {
            "name" : "GetMyTable3",
            "parameters" : {
              "type" : "object",
              "properties" : {
                "offset" : {
                  "type" : "integer"
                },
                "limit" : {
                  "type" : "integer"
                }
              },
              "required" : [ ]
            }
          },
          "format" : "JSON",
          "apiQuery" : {
            "query" : "query MyTable3($limit: Int = 10, $offset: Int = 0) {\nMyTable3(limit: $limit, offset: $offset) {\nid\nhello\n}\n\n}",
            "queryName" : "MyTable3",
            "operationType" : "QUERY"
          },
          "mcpMethod" : "TOOL",
          "restMethod" : "GET",
          "uriTemplate" : "queries/MyTable3{?offset,limit}"
        }
      ],
      "schema" : {
        "type" : "string",
        "schema" : "\"An RFC-3339 compliant Full Date Scalar\"\nscalar Date\n\n\"A DateTime scalar that handles both full RFC3339 and shorter timestamp formats\"\nscalar DateTime\n\n\"A JSON scalar\"\nscalar JSON\n\n\"24-hour clock time value string in the format `hh:mm:ss` or `hh:mm:ss.sss`.\"\nscalar LocalTime\n\n\"A 64-bit signed integer\"\nscalar Long\n\ntype MyTable1 {\n  id: Long!\n  hello: String!\n}\n\ntype MyTable2 {\n  id: Long!\n  hello: String!\n}\n\ntype MyTable3 {\n  id: Long!\n  hello: String!\n}\n\ntype Query {\n  MyTable1(limit: Int = 10, offset: Int = 0): [MyTable1!]\n  MyTable2(limit: Int = 10, offset: Int = 0): [MyTable2!]\n  MyTable3(limit: Int = 10, offset: Int = 0): [MyTable3!]\n}\n\nenum _McpMethodType {\n  NONE\n  TOOL\n  RESOURCE\n}\n\nenum _RestMethodType {\n  NONE\n  GET\n  POST\n}\n\ndirective @api(mcp: _McpMethodType, rest: _RestMethodType, uri: String) on QUERY | MUTATION | FIELD_DEFINITION\n"
      }
    }
  }
}
