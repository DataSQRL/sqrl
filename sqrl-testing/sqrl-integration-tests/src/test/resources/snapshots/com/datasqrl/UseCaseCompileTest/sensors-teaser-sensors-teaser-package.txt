>>>pipeline_explain.txt
=== SecReading
ID:     default_catalog.default_database.SecReading
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.SensorReading
Annotations:
 - features: STREAM_WINDOW_AGGREGATION (feature)
 - stream-root: SensorReading__def
 - sort: [1 DESC-nulls-last]
Primary Key: -
Timestamp  : timeSec
Schema:
 - sensorid: BIGINT NOT NULL
 - timeSec: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - temp: DOUBLE NOT NULL
Plan:
LogicalProject(sensorid=[$0], timeSec=[$3], temp=[$4])
  LogicalAggregate(group=[{0, 1, 2, 3}], temp=[AVG($4)])
    LogicalProject(sensorid=[$0], window_start=[$5], window_end=[$6], timeSec=[$7], temperature=[$2])
      LogicalTableFunctionScan(invocation=[TUMBLE(DESCRIPTOR($4), 1000:INTERVAL SECOND)], rowType=[RecordType(BIGINT sensorid, BIGINT time, DOUBLE temperature, DOUBLE humidity, TIMESTAMP_LTZ(3) *ROWTIME* timestamp, TIMESTAMP(3) window_start, TIMESTAMP(3) window_end, TIMESTAMP_LTZ(3) *ROWTIME* window_time)])
        LogicalProject(sensorid=[$0], time=[$1], temperature=[$2], humidity=[$3], timestamp=[$4])
          LogicalTableScan(table=[[default_catalog, default_database, SensorReading]])
SQL: CREATE VIEW SecReading AS  SELECT sensorid, window_time as timeSec,
        avg(temperature) as temp
    FROM TABLE(TUMBLE(TABLE SensorReading, DESCRIPTOR(`timestamp`), INTERVAL '1' SECONDS))
    GROUP BY sensorid, window_start, window_end, window_time
    ORDER BY timeSec DESC;

=== SensorMaxTemp
ID:     default_catalog.default_database.SensorMaxTemp
Type:   state
Stage:  flink
Inputs: default_catalog.default_database._SensorMaxTempWindow
Annotations:
 - mostRecentDistinct: true
 - stream-root: SensorReading__def
Primary Key: sensorid
Timestamp  : window_time
Schema:
 - sensorid: BIGINT NOT NULL
 - window_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - maxTemp: DOUBLE NOT NULL
Plan:
LogicalProject(sensorid=[$0], window_time=[$1], maxTemp=[$2])
  LogicalFilter(condition=[=($3, 1)])
    LogicalProject(sensorid=[$0], window_time=[$1], maxTemp=[$2], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $1 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, _SensorMaxTempWindow]])
SQL: CREATE VIEW `SensorMaxTemp`
AS
SELECT `sensorid`, `window_time`, `maxTemp`
FROM (SELECT `sensorid`, `window_time`, `maxTemp`, ROW_NUMBER() OVER (PARTITION BY `sensorid` ORDER BY `window_time` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_SensorMaxTempWindow`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== SensorReading
ID:     default_catalog.default_database.SensorReading
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.SensorReading__def
Annotations:
 - stream-root: SensorReading__def
Primary Key: sensorid, time
Timestamp  : timestamp
Schema:
 - sensorid: BIGINT NOT NULL
 - time: BIGINT NOT NULL
 - temperature: DOUBLE NOT NULL
 - humidity: DOUBLE NOT NULL
 - timestamp: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(sensorid=[$0], time=[$1], temperature=[$2], humidity=[$3], timestamp=[$4])
  LogicalWatermarkAssigner(rowtime=[timestamp], watermark=[-($4, 1:INTERVAL SECOND)])
    LogicalProject(sensorid=[$0], time=[$1], temperature=[$2], humidity=[$3], timestamp=[EPOCHMILLITOTIMESTAMP($1)])
      LogicalTableScan(table=[[default_catalog, default_database, SensorReading__def]])
SQL: CREATE VIEW `SensorReading`
AS
SELECT *
FROM `default_catalog`.`default_database`.`SensorReading__def`
=== _SensorMaxTempWindow
ID:     default_catalog.default_database._SensorMaxTempWindow
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.SecReading
Annotations:
 - features: STREAM_WINDOW_AGGREGATION (feature)
 - stream-root: SensorReading__def
Primary Key: -
Timestamp  : window_time
Schema:
 - sensorid: BIGINT NOT NULL
 - window_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - maxTemp: DOUBLE NOT NULL
Plan:
LogicalProject(sensorid=[$0], window_time=[$3], maxTemp=[$4])
  LogicalAggregate(group=[{0, 1, 2, 3}], maxTemp=[MAX($4)])
    LogicalProject(sensorid=[$0], window_start=[$3], window_end=[$4], window_time=[$5], temp=[$2])
      LogicalTableFunctionScan(invocation=[HOP(DESCRIPTOR($1), 5000:INTERVAL SECOND, 60000:INTERVAL MINUTE)], rowType=[RecordType(BIGINT sensorid, TIMESTAMP_LTZ(3) *ROWTIME* timeSec, DOUBLE temp, TIMESTAMP(3) window_start, TIMESTAMP(3) window_end, TIMESTAMP_LTZ(3) *ROWTIME* window_time)])
        LogicalProject(sensorid=[$0], timeSec=[$1], temp=[$2])
          LogicalTableScan(table=[[default_catalog, default_database, SecReading]])
SQL: CREATE VIEW _SensorMaxTempWindow AS  SELECT sensorid, window_time, max(temp) as maxTemp
    FROM TABLE(HOP(TABLE SecReading, DESCRIPTOR(timeSec), INTERVAL '5' SECONDS, INTERVAL '1' MINUTES))
    GROUP BY sensorid, window_start, window_end, window_time;

>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `SensorReading__schema` (
  `sensorid` BIGINT NOT NULL,
  `time` BIGINT NOT NULL,
  `temperature` DOUBLE NOT NULL,
  `humidity` DOUBLE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `SensorReading__def` (
  `timestamp` AS EPOCHMILLITOTIMESTAMP(`time`),
  PRIMARY KEY (`sensorid`, `time`) NOT ENFORCED,
  WATERMARK FOR `timestamp` AS `timestamp` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-csv',
  'path' = '${DATA_PATH}/sensorreading.csv.gz',
  'connector' = 'filesystem',
  'flexible-csv.skip-header' = 'true'
)
LIKE `SensorReading__schema`;
CREATE VIEW `SensorReading`
AS
SELECT *
FROM `default_catalog`.`default_database`.`SensorReading__def`;
CREATE VIEW `SecReading`
AS
SELECT `sensorid`, `window_time` AS `timeSec`, AVG(`temperature`) AS `temp`
FROM TABLE(TUMBLE(TABLE `SensorReading`, DESCRIPTOR(`timestamp`), INTERVAL '1' SECOND))
GROUP BY `sensorid`, `window_start`, `window_end`, `window_time`;
CREATE VIEW `_SensorMaxTempWindow`
AS
SELECT `sensorid`, `window_time`, MAX(`temp`) AS `maxTemp`
FROM TABLE(HOP(TABLE `SecReading`, DESCRIPTOR(`timeSec`), INTERVAL '5' SECOND, INTERVAL '1' MINUTE))
GROUP BY `sensorid`, `window_start`, `window_end`, `window_time`;
CREATE VIEW `SensorMaxTemp`
AS
SELECT `sensorid`, `window_time`, `maxTemp`
FROM (SELECT `sensorid`, `window_time`, `maxTemp`, ROW_NUMBER() OVER (PARTITION BY `sensorid` ORDER BY `window_time` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_SensorMaxTempWindow`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `SecReadingTest`
AS
SELECT *
FROM `SecReading`;
CREATE VIEW `SensorMaxTempTest`
AS
SELECT *
FROM `SensorMaxTemp`;
CREATE TABLE `SecReading_1` (
  `sensorid` BIGINT NOT NULL,
  `timeSec` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `temp` DOUBLE NOT NULL,
  `__pk_hash` CHAR(32) CHARACTER SET `UTF-16LE`,
  PRIMARY KEY (`__pk_hash`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'password' = '${JDBC_PASSWORD}',
  'driver' = 'org.postgresql.Driver',
  'username' = '${JDBC_USERNAME}',
  'url' = 'jdbc:postgresql://${JDBC_AUTHORITY}',
  'table-name' = 'SecReading_1'
);
CREATE TABLE `SensorMaxTemp_2` (
  `sensorid` BIGINT NOT NULL,
  `window_time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `maxTemp` DOUBLE NOT NULL,
  PRIMARY KEY (`sensorid`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'password' = '${JDBC_PASSWORD}',
  'driver' = 'org.postgresql.Driver',
  'username' = '${JDBC_USERNAME}',
  'url' = 'jdbc:postgresql://${JDBC_AUTHORITY}',
  'table-name' = 'SensorMaxTemp_2'
);
CREATE TABLE `SensorReading_3` (
  `sensorid` BIGINT NOT NULL,
  `time` BIGINT NOT NULL,
  `temperature` DOUBLE NOT NULL,
  `humidity` DOUBLE NOT NULL,
  `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`sensorid`, `time`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'password' = '${JDBC_PASSWORD}',
  'driver' = 'org.postgresql.Driver',
  'username' = '${JDBC_USERNAME}',
  'url' = 'jdbc:postgresql://${JDBC_AUTHORITY}',
  'table-name' = 'SensorReading_3'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`SecReading_1`
(SELECT `sensorid`, `timeSec`, `temp`, HASHCOLUMNS(`sensorid`, `timeSec`, `temp`) AS `__pk_hash`
 FROM `default_catalog`.`default_database`.`SecReading`)
;
INSERT INTO `default_catalog`.`default_database`.`SensorMaxTemp_2`
 (SELECT *
  FROM `default_catalog`.`default_database`.`_SensorMaxTempWindow`)
 ;
 INSERT INTO `default_catalog`.`default_database`.`SensorReading_3`
  (SELECT *
   FROM `default_catalog`.`default_database`.`SensorReading`)
  ;
  END
>>>kafka.json
{
  "topics" : [ ]
}
>>>postgres-schema.sql
CREATE TABLE IF NOT EXISTS "SecReading_1" ("sensorid" BIGINT NOT NULL, "timeSec" TIMESTAMP WITH TIME ZONE NOT NULL, "temp" DOUBLE PRECISION NOT NULL, "__pk_hash" TEXT  , PRIMARY KEY ("__pk_hash"));
CREATE TABLE IF NOT EXISTS "SensorMaxTemp_2" ("sensorid" BIGINT NOT NULL, "window_time" TIMESTAMP WITH TIME ZONE NOT NULL, "maxTemp" DOUBLE PRECISION NOT NULL , PRIMARY KEY ("sensorid"));
CREATE TABLE IF NOT EXISTS "SensorReading_3" ("sensorid" BIGINT NOT NULL, "time" BIGINT NOT NULL, "temperature" DOUBLE PRECISION NOT NULL, "humidity" DOUBLE PRECISION NOT NULL, "timestamp" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("sensorid","time"))
>>>postgres-views.sql
CREATE OR REPLACE VIEW "SecReading"("sensorid", "timeSec", "temp") AS SELECT "sensorid", "timeSec", "temp"
FROM (SELECT "sensorid", "timeSec", "temp", "__pk_hash"
  FROM "SecReading_1"
  ORDER BY "timeSec" DESC NULLS LAST) AS "t1";
CREATE OR REPLACE VIEW "SensorMaxTemp"("sensorid", "window_time", "maxTemp") AS SELECT *
FROM "SensorMaxTemp_2";
CREATE OR REPLACE VIEW "SensorReading"("sensorid", "time", "temperature", "humidity", "timestamp") AS SELECT *
FROM "SensorReading_3"
>>>vertx.json
{ }
