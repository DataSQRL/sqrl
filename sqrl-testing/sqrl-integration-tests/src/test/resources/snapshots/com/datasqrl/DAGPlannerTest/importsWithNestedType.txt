>>>pipeline_explain.txt
=== Orders
ID:     default_catalog.default_database.Orders
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Orders__base
Annotations:
 - features: DENORMALIZE (feature)
 - stream-root: Orders
Primary Key: id, time
Timestamp  : time
Schema:
 - id: BIGINT NOT NULL
 - customerid: BIGINT NOT NULL
 - time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - entries: RecordType:peek_no_expand(BIGINT NOT NULL productid, BIGINT NOT NULL quantity, DOUBLE NOT NULL unit_price, DOUBLE discount) NOT NULL ARRAY NOT NULL
Plan:
LogicalWatermarkAssigner(rowtime=[time], watermark=[-($2, 1:INTERVAL SECOND)])
  LogicalTableScan(table=[[default_catalog, default_database, Orders]])
SQL: CREATE VIEW `Orders__view`
AS
SELECT `Orders`.`id`, `Orders`.`customerid`, `Orders`.`time`, `Orders`.`entries`
FROM `default_catalog`.`default_database`.`Orders` AS `Orders`
>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `Orders__schema` (
  `id` BIGINT NOT NULL,
  `customerid` BIGINT NOT NULL,
  `time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `entries` ROW(`productid` BIGINT NOT NULL, `quantity` BIGINT NOT NULL, `unit_price` DOUBLE NOT NULL, `discount` DOUBLE) NOT NULL ARRAY NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `Orders` (
  PRIMARY KEY (`id`, `time`) NOT ENFORCED,
  WATERMARK FOR `time` AS `time` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = 'file:/mock',
  'source.monitor-interval' = '10 sec',
  'connector' = 'filesystem'
)
LIKE `Orders__schema`;
CREATE TABLE `Orders_1` (
  `id` BIGINT NOT NULL,
  `customerid` BIGINT NOT NULL,
  `time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `entries` RAW('com.datasqrl.flinkrunner.stdlib.json.FlinkJsonType', 'AERjb20uZGF0YXNxcmwuZmxpbmtydW5uZXIuc3RkbGliLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXJTbmFwc2hvdAAAAAM='),
  PRIMARY KEY (`id`, `time`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'driver' = 'org.postgresql.Driver',
  'password' = '${JDBC_PASSWORD}',
  'table-name' = 'Orders_1',
  'url' = 'jdbc:postgresql://${JDBC_AUTHORITY}',
  'username' = '${JDBC_USERNAME}'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`Orders_1`
(SELECT `id`, `customerid`, `time`, `to_jsonb`(`entries`) AS `entries`
 FROM `default_catalog`.`default_database`.`Orders`)
;
END
>>>kafka.json
{
  "topics" : [ ]
}
>>>postgres.json
{
  "statements" : [
    {
      "name" : "Orders_1",
      "type" : "TABLE",
      "sql" : "CREATE TABLE IF NOT EXISTS \"Orders_1\" (\"id\" BIGINT NOT NULL, \"customerid\" BIGINT NOT NULL, \"time\" TIMESTAMP WITH TIME ZONE NOT NULL, \"entries\" JSONB  , PRIMARY KEY (\"id\",\"time\"))",
      "fields" : [
        {
          "name" : "id",
          "type" : "BIGINT",
          "nullable" : false
        },
        {
          "name" : "customerid",
          "type" : "BIGINT",
          "nullable" : false
        },
        {
          "name" : "time",
          "type" : "TIMESTAMP WITH TIME ZONE",
          "nullable" : false
        },
        {
          "name" : "entries",
          "type" : "JSONB",
          "nullable" : true
        }
      ]
    },
    {
      "name" : "Orders",
      "type" : "VIEW",
      "sql" : "CREATE OR REPLACE VIEW \"Orders\"(\"id\", \"customerid\", \"time\", \"entries\") AS SELECT *\nFROM \"Orders_1\"",
      "fields" : [
        {
          "name" : "id",
          "type" : "BIGINT",
          "nullable" : false
        },
        {
          "name" : "customerid",
          "type" : "BIGINT",
          "nullable" : false
        },
        {
          "name" : "time",
          "type" : "TIMESTAMP WITH TIME ZONE",
          "nullable" : false
        },
        {
          "name" : "entries",
          "type" : "JSONB",
          "nullable" : true
        }
      ]
    }
  ]
}
