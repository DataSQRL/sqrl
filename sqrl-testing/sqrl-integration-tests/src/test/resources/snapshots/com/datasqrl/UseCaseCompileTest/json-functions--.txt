>>>pipeline_explain.txt
=== Json
ID:     default_catalog.default_database.Json
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Json__def
Annotations:
 - stream-root: Json__def
Primary Key: id
Timestamp  : timestamp
Schema:
 - id: BIGINT NOT NULL
 - val: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - timestamp: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], val=[$1], timestamp=[$2])
  LogicalWatermarkAssigner(rowtime=[timestamp], watermark=[-($2, 1:INTERVAL SECOND)])
    LogicalTableScan(table=[[default_catalog, default_database, Json__def]])
SQL: CREATE VIEW `Json`
AS
SELECT *
FROM `default_catalog`.`default_database`.`Json__def`
=== UnmodifiedJsonData
ID:     default_catalog.default_database.UnmodifiedJsonData
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Json
Annotations:
 - stream-root: Json__def
 - sort: [0 ASC-nulls-first]
Primary Key: id
Timestamp  : -
Schema:
 - id: BIGINT NOT NULL
 - val: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - json_col: RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI=')
 - json_col_2: RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI=')
 - json_col_3: RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI=')
 - json_col_4: RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI=')
Plan:
LogicalProject(id=[$0], val=[$1], json_col=[TOJSON('{"a": 1}')], json_col_2=[TOJSON('{"a": 2}')], json_col_3=[TOJSON('{"b": 1}')], json_col_4=[TOJSON('{"b": 2}')])
  LogicalTableScan(table=[[default_catalog, default_database, Json]])
SQL: CREATE VIEW UnmodifiedJsonData AS  SELECT id,
                             val,
                             TOJSON('{"a": 1}') AS json_col,
                             TOJSON('{"a": 2}') AS json_col_2,
                             TOJSON('{"b": 1}') AS json_col_3,
                             TOJSON('{"b": 2}') AS json_col_4
                     FROM Json
                     ORDER BY id;

>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `Json__schema` (
  `id` BIGINT NOT NULL,
  `val` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `Json__def` (
  PRIMARY KEY (`id`) NOT ENFORCED,
  WATERMARK FOR `timestamp` AS `timestamp` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/json.jsonl',
  'connector' = 'filesystem'
)
LIKE `Json__schema`;
CREATE VIEW `Json`
AS
SELECT *
FROM `default_catalog`.`default_database`.`Json__def`;
CREATE VIEW `UnmodifiedJsonData`
AS
SELECT `id`, `val`, TOJSON('{"a": 1}') AS `json_col`, TOJSON('{"a": 2}') AS `json_col_2`, TOJSON('{"b": 1}') AS `json_col_3`, TOJSON('{"b": 2}') AS `json_col_4`
FROM `Json`;
CREATE VIEW `JsonArrayTest`
AS
SELECT `id`, JSONARRAY(`id`, `json_col`) AS `json_array_string_function`, JSONARRAY(`json_col`, `json_col_2`) AS `json_array_json_function`
FROM `UnmodifiedJsonData`;
CREATE VIEW `JsonConcatTest`
AS
SELECT `id`, JSONCONCAT(`json_col`, `json_col_2`) AS `json_concat_same_key_function`, JSONCONCAT(`json_col`, `json_col_3`) AS `json_concat_diff_key_function`
FROM `UnmodifiedJsonData`;
CREATE VIEW `JsonExistsTest`
AS
SELECT `id`, JSONEXISTS(`json_col`, '$.a') AS `json_exists_function`, JSONEXISTS(`json_col`, '$.nonExistentPath') AS `json_not_exists_function`
FROM `UnmodifiedJsonData`;
CREATE VIEW `JsonExtractTest`
AS
SELECT `id`, JSONEXTRACT(`json_col`, '$.a') AS `json_extract_function`, JSONEXTRACT(`json_col`, '$.nonExistentPath') AS `json_extract_not_exists_function`, JSONEXTRACT(`json_col`, '$.nonExistentPath', 'default') AS `json_extract_with_default_function`, JSONEXTRACT(`json_col`, '$.a', 100) AS `json_extract_with_default_int_function`
FROM `UnmodifiedJsonData`;
CREATE VIEW `JsonArrayAggTest`
AS
SELECT `val`, JSONARRAYAGG(`json_col`) AS `json_array_agg_function`
FROM `UnmodifiedJsonData`
GROUP BY `val`;
CREATE VIEW `JsonObjectAggTest`
AS
SELECT `val`, JSONOBJECTAGG('key', `json_col`) AS `json_object_agg_function`
FROM `UnmodifiedJsonData`
GROUP BY `val`;
CREATE VIEW `ToJsonTest`
AS
SELECT `id`, TOJSON(`json_col`) AS `to_json_function`
FROM `UnmodifiedJsonData`;
CREATE TABLE `Json_1` (
  `id` BIGINT NOT NULL,
  `val` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'password' = '${JDBC_PASSWORD}',
  'driver' = 'org.postgresql.Driver',
  'username' = '${JDBC_USERNAME}',
  'url' = 'jdbc:postgresql://${JDBC_URL}',
  'table-name' = 'Json_1'
);
CREATE TABLE `UnmodifiedJsonData_2` (
  `id` BIGINT NOT NULL,
  `val` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `json_col` RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI='),
  `json_col_2` RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI='),
  `json_col_3` RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI='),
  `json_col_4` RAW('com.datasqrl.json.FlinkJsonType', 'ADFjb20uZGF0YXNxcmwuanNvbi5GbGlua0pzb25UeXBlU2VyaWFsaXplclNuYXBzaG90AAAAAQApY29tLmRhdGFzcXJsLmpzb24uRmxpbmtKc29uVHlwZVNlcmlhbGl6ZXI='),
  PRIMARY KEY (`id`) NOT ENFORCED
) WITH (
  'connector' = 'jdbc-sqrl',
  'password' = '${JDBC_PASSWORD}',
  'driver' = 'org.postgresql.Driver',
  'username' = '${JDBC_USERNAME}',
  'url' = 'jdbc:postgresql://${JDBC_URL}',
  'table-name' = 'UnmodifiedJsonData_2'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`Json_1`
(SELECT *
 FROM `default_catalog`.`default_database`.`Json`)
;
INSERT INTO `default_catalog`.`default_database`.`UnmodifiedJsonData_2`
 (SELECT *
  FROM `default_catalog`.`default_database`.`UnmodifiedJsonData`)
 ;
 END
>>>kafka.json
{
  "topics" : [ ]
}
>>>postgres-schema.sql
CREATE TABLE IF NOT EXISTS "Json_1" ("id" BIGINT NOT NULL, "val" TEXT NOT NULL, "timestamp" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"));
CREATE TABLE IF NOT EXISTS "UnmodifiedJsonData_2" ("id" BIGINT NOT NULL, "val" TEXT NOT NULL, "json_col" JSONB , "json_col_2" JSONB , "json_col_3" JSONB , "json_col_4" JSONB  , PRIMARY KEY ("id"))
>>>postgres-views.sql
CREATE OR REPLACE VIEW "Json"("id", "val", "timestamp") AS SELECT *
FROM "Json_1";
CREATE OR REPLACE VIEW "UnmodifiedJsonData"("id", "val", "json_col", "json_col_2", "json_col_3", "json_col_4") AS SELECT *
FROM (SELECT "id", "val", "json_col", "json_col_2", "json_col_3", "json_col_4"
  FROM "UnmodifiedJsonData_2"
  ORDER BY "id" NULLS FIRST) AS "t1"
>>>vertx.json
{ }
