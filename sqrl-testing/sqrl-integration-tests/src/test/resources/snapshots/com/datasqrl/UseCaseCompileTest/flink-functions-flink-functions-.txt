>>>pipeline_explain.txt
=== Numbers
ID:     numbers_2
Type:   stream
Stage:  flink
Primary Key: id
Timestamp  : timestamp
Schema:
 - id: BIGINT NOT NULL
 - x: DOUBLE NOT NULL
 - y: DOUBLE NOT NULL
 - timestamp: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
Plan:
LogicalTableScan(table=[[numbers_1]])

=== UnmodifiedData
ID:     unmodifieddata_1
Type:   stream
Stage:  flink
Inputs: numbers_2
Primary Key: id
Timestamp  : _timestamp
Schema:
 - id: BIGINT NOT NULL
 - x: DOUBLE NOT NULL
 - y: DOUBLE NOT NULL
 - _timestamp: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
Post Processors:
 - sort: #0: id BIGINT ASC
Plan:
LogicalProject(id=[$0], x=[$2], y=[$3], _timestamp=[$1])
  LogicalAggregate(group=[{0, 3}], x=[AVG($1)], y=[AVG($2)]) hints[TumbleAggregationHint options:[3, INSTANT, 3, 1, 0]]
    LogicalTableScan(table=[[numbers_2]])

>>>flink.json
{
  "flinkSql" : [
    "CREATE TEMPORARY TABLE `numbers_1` (\n  `id` BIGINT NOT NULL,\n  `x` DOUBLE NOT NULL,\n  `y` DOUBLE NOT NULL,\n  `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,\n  PRIMARY KEY (`id`) NOT ENFORCED,\n  WATERMARK FOR `timestamp` AS `timestamp` - INTERVAL '0.001' SECOND\n) WITH (\n  'format' = 'flexible-json',\n  'path' = '${DATA_PATH}/numbers.jsonl',\n  'connector' = 'filesystem'\n);",
    "CREATE TEMPORARY TABLE `unmodifieddata_1` (\n  `id` BIGINT NOT NULL,\n  `x` DOUBLE NOT NULL,\n  `y` DOUBLE NOT NULL,\n  `_timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,\n  PRIMARY KEY (`id`) NOT ENFORCED\n) WITH (\n  'password' = '${JDBC_PASSWORD}',\n  'connector' = 'jdbc-sqrl',\n  'driver' = 'org.postgresql.Driver',\n  'table-name' = 'unmodifieddata_1',\n  'url' = '${JDBC_URL}',\n  'username' = '${JDBC_USERNAME}'\n);",
    "CREATE VIEW `table$1`\nAS\nSELECT *\nFROM `numbers_1`;",
    "CREATE VIEW `table$2`\nAS\nSELECT `id`, AVG(`x`) AS `x`, AVG(`y`) AS `y`, `window_time` AS `_timestamp`\nFROM TABLE(TUMBLE(TABLE `table$1`, DESCRIPTOR(`timestamp`), INTERVAL '0.001' SECOND(1))) AS `t`\nGROUP BY `id`, `window_start`, `window_end`, `window_time`;",
    "EXECUTE STATEMENT SET BEGIN\nINSERT INTO `unmodifieddata_1`\n(SELECT *\n FROM `table$2`)\n;\nEND;"
  ],
  "connectors" : [
    "jdbc-sqrl",
    "filesystem"
  ],
  "formats" : [
    "flexible-json"
  ]
}
>>>kafka.json
{
  "topics" : [ ]
}
>>>postgres.json
{
  "ddl" : [
    {
      "name" : "unmodifieddata_1",
      "columns" : [
        "\"id\" BIGINT NOT NULL",
        "\"x\" DOUBLE PRECISION NOT NULL",
        "\"y\" DOUBLE PRECISION NOT NULL",
        "\"_timestamp\" TIMESTAMP WITH TIME ZONE NOT NULL"
      ],
      "primaryKeys" : [
        "\"id\""
      ],
      "sql" : "CREATE TABLE IF NOT EXISTS unmodifieddata_1 (\"id\" BIGINT NOT NULL,\"x\" DOUBLE PRECISION NOT NULL,\"y\" DOUBLE PRECISION NOT NULL,\"_timestamp\" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY (\"id\"));"
    }
  ],
  "views" : [ ]
}
>>>vertx.json
{
  "model" : {
    "coords" : [
      {
        "type" : "args",
        "parentType" : "Query",
        "fieldName" : "UnmodifiedData",
        "matchs" : [
          {
            "arguments" : [
              {
                "type" : "variable",
                "type" : "variable",
                "path" : "id"
              }
            ],
            "query" : {
              "type" : "JdbcQuery",
              "type" : "JdbcQuery",
              "sql" : "SELECT *\nFROM \"unmodifieddata_1\"\nWHERE \"id\" = $1\nORDER BY \"id\"",
              "parameters" : [
                {
                  "type" : "arg",
                  "type" : "arg",
                  "path" : "id"
                }
              ]
            }
          }
        ]
      }
    ],
    "mutations" : [ ],
    "subscriptions" : [ ],
    "schema" : {
      "type" : "string",
      "type" : "string",
      "schema" : "\"An RFC-3339 compliant DateTime Scalar\"\nscalar DateTime\n\ntype Query {\n    UnmodifiedData(id: Int!): [UnmodifiedData!]\n}\n\ntype UnmodifiedData {\n    id: Int!\n    x: Float!\n    y: Float!\n}\n\n"
    }
  }
}
