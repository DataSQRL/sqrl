>>>pipeline_explain.txt
=== ApplicationInfo
ID:     default_catalog.default_database.ApplicationInfo
Type:   state
Stage:  iceberg
Inputs: default_catalog.default_database._Applications, default_catalog.default_database._LoanTypes
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id0: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at0: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id2: BIGINT
Plan:
LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6], id0=[$7], name=[$8], description=[$9], interest_rate=[$10], max_amount=[$11], min_amount=[$12], max_duration=[$13], min_duration=[$14], updated_at0=[$15], id2=[$16])
  LogicalJoin(condition=[=($16, $1)], joinType=[left])
    LogicalJoin(condition=[=($7, $2)], joinType=[inner])
      LogicalTableScan(table=[[default_catalog, default_database, _Applications]])
      LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
    LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
SQL: CREATE VIEW ApplicationInfo AS  SELECT a.*, t.*, t2.id AS id2 FROM _Applications a
    JOIN _LoanTypes t ON t.id = a.loan_type_id
    LEFT JOIN _LoanTypes t2 ON t2.id = a.customer_id;

=== ApplicationStatus
ID:     default_catalog.default_database.ApplicationStatus
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationUpdates, default_catalog.default_database._Applications, default_catalog.default_database._LoanTypes
Annotations:
 - stream-root: _ApplicationUpdates
Primary Key: -
Timestamp  : event_time
Schema:
 - status: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - message: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - event_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
Plan:
LogicalProject(status=[$1], message=[$2], event_time=[$3], id=[$4], customer_id=[$5], loan_type_id=[$6], amount=[$7], duration=[$8], max_amount=[$15], min_amount=[$16])
  LogicalCorrelate(correlation=[$cor3], joinType=[inner], requiredColumns=[{3, 6}])
    LogicalCorrelate(correlation=[$cor2], joinType=[inner], requiredColumns=[{0, 3}])
      LogicalTableScan(table=[[default_catalog, default_database, _ApplicationUpdates]])
      LogicalFilter(condition=[=($0, $cor2.loan_application_id)])
        LogicalSnapshot(period=[$cor2.event_time])
          LogicalTableScan(table=[[default_catalog, default_database, _Applications]])
    LogicalFilter(condition=[=($0, $cor3.loan_type_id)])
      LogicalSnapshot(period=[$cor3.event_time])
        LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
SQL: CREATE VIEW ApplicationStatus AS  SELECT u.status, u.message, u.event_time, a.id, a.customer_id, a.loan_type_id,
                            a.amount, a.duration, t.max_amount, t.min_amount
                     FROM _ApplicationUpdates u JOIN _Applications FOR SYSTEM_TIME AS OF u.`event_time` a ON a.id = u.loan_application_id
                                               JOIN _LoanTypes FOR SYSTEM_TIME AS OF u.`event_time` t ON t.id = a.loan_type_id;

=== _ApplicationUpdates
ID:     default_catalog.default_database._ApplicationUpdates
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationUpdates__base
Annotations:
 - stream-root: _ApplicationUpdates
Primary Key: loan_application_id, event_time
Timestamp  : event_time
Schema:
 - loan_application_id: BIGINT NOT NULL
 - status: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - message: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - event_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalWatermarkAssigner(rowtime=[event_time], watermark=[$3])
  LogicalTableScan(table=[[default_catalog, default_database, _ApplicationUpdates]])
SQL: CREATE VIEW `_ApplicationUpdates__view`
AS
SELECT `_ApplicationUpdates`.`loan_application_id`, `_ApplicationUpdates`.`status`, `_ApplicationUpdates`.`message`, `_ApplicationUpdates`.`event_time`
FROM `default_catalog`.`default_database`.`_ApplicationUpdates` AS `_ApplicationUpdates`
=== _Applications
ID:     default_catalog.default_database._Applications
Type:   state
Stage:  flink
Inputs: default_catalog.default_database._ApplicationsStream
Annotations:
 - mostRecentDistinct: true
 - stream-root: _ApplicationsStream
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6])
  LogicalFilter(condition=[=($7, 1)])
    LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $6 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, _ApplicationsStream]])
SQL: CREATE VIEW `_Applications`
AS
SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`
FROM (SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== _ApplicationsStream
ID:     default_catalog.default_database._ApplicationsStream
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationsStream__base
Annotations:
 - stream-root: _ApplicationsStream
Primary Key: id, updated_at
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalWatermarkAssigner(rowtime=[updated_at], watermark=[-($6, 1:INTERVAL SECOND)])
  LogicalTableScan(table=[[default_catalog, default_database, _ApplicationsStream]])
SQL: CREATE VIEW `_ApplicationsStream__view`
AS
SELECT `_ApplicationsStream`.`id`, `_ApplicationsStream`.`customer_id`, `_ApplicationsStream`.`loan_type_id`, `_ApplicationsStream`.`amount`, `_ApplicationsStream`.`duration`, `_ApplicationsStream`.`application_date`, `_ApplicationsStream`.`updated_at`
FROM `default_catalog`.`default_database`.`_ApplicationsStream` AS `_ApplicationsStream`
=== _LoanTypes
ID:     default_catalog.default_database._LoanTypes
Type:   state
Stage:  flink
Inputs: default_catalog.default_database._LoanTypesStream
Annotations:
 - mostRecentDistinct: true
 - stream-root: _LoanTypesStream
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], name=[$1], description=[$2], interest_rate=[$3], max_amount=[$4], min_amount=[$5], max_duration=[$6], min_duration=[$7], updated_at=[$8])
  LogicalFilter(condition=[=($9, 1)])
    LogicalProject(id=[$0], name=[$1], description=[$2], interest_rate=[$3], max_amount=[$4], min_amount=[$5], max_duration=[$6], min_duration=[$7], updated_at=[$8], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $8 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, _LoanTypesStream]])
SQL: CREATE VIEW `_LoanTypes`
AS
SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`
FROM (SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_LoanTypesStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== _LoanTypesStream
ID:     default_catalog.default_database._LoanTypesStream
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._LoanTypesStream__base
Annotations:
 - stream-root: _LoanTypesStream
Primary Key: id, updated_at
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalWatermarkAssigner(rowtime=[updated_at], watermark=[-($8, 1:INTERVAL SECOND)])
  LogicalTableScan(table=[[default_catalog, default_database, _LoanTypesStream]])
SQL: CREATE VIEW `_LoanTypesStream__view`
AS
SELECT `_LoanTypesStream`.`id`, `_LoanTypesStream`.`name`, `_LoanTypesStream`.`description`, `_LoanTypesStream`.`interest_rate`, `_LoanTypesStream`.`max_amount`, `_LoanTypesStream`.`min_amount`, `_LoanTypesStream`.`max_duration`, `_LoanTypesStream`.`min_duration`, `_LoanTypesStream`.`updated_at`
FROM `default_catalog`.`default_database`.`_LoanTypesStream` AS `_LoanTypesStream`
>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `_ApplicationsStream__schema` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_ApplicationsStream` (
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED,
  WATERMARK FOR `updated_at` AS `updated_at` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/applications.jsonl',
  'source.monitor-interval' = '10 sec',
  'connector' = 'filesystem'
)
LIKE `_ApplicationsStream__schema`;
CREATE TEMPORARY TABLE `_LoanTypesStream__schema` (
  `id` BIGINT NOT NULL,
  `name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `description` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `interest_rate` DOUBLE NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `max_duration` BIGINT NOT NULL,
  `min_duration` BIGINT NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_LoanTypesStream` (
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED,
  WATERMARK FOR `updated_at` AS `updated_at` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/loan_types.jsonl',
  'source.monitor-interval' = '10 sec',
  'connector' = 'filesystem'
)
LIKE `_LoanTypesStream__schema`;
CREATE TEMPORARY TABLE `_ApplicationUpdates__schema` (
  `loan_application_id` BIGINT NOT NULL,
  `status` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `message` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `event_time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_ApplicationUpdates` (
  PRIMARY KEY (`loan_application_id`, `event_time`) NOT ENFORCED,
  WATERMARK FOR `event_time` AS `event_time`
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/application_updates.jsonl',
  'connector' = 'filesystem'
)
LIKE `_ApplicationUpdates__schema`;
CREATE VIEW `_Applications`
AS
SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`
FROM (SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `_LoanTypes`
AS
SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`
FROM (SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_LoanTypesStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `ApplicationStatus`
AS
SELECT `u`.`status`, `u`.`message`, `u`.`event_time`, `a`.`id`, `a`.`customer_id`, `a`.`loan_type_id`, `a`.`amount`, `a`.`duration`, `t`.`max_amount`, `t`.`min_amount`
FROM `_ApplicationUpdates` AS `u`
 INNER JOIN `_Applications` FOR SYSTEM_TIME AS OF `u`.`event_time` AS `a` ON `a`.`id` = `u`.`loan_application_id`
 INNER JOIN `_LoanTypes` FOR SYSTEM_TIME AS OF `u`.`event_time` AS `t` ON `t`.`id` = `a`.`loan_type_id`;
CREATE VIEW `ApplicationInfo`
AS
SELECT `a`.*, `t`.*, `t2`.`id` AS `id2`
FROM `_Applications` AS `a`
 INNER JOIN `_LoanTypes` AS `t` ON `t`.`id` = `a`.`loan_type_id`
 LEFT JOIN `_LoanTypes` AS `t2` ON `t2`.`id` = `a`.`customer_id`;
CREATE VIEW `ApplicationInfoTest`
AS
SELECT COUNT(1) AS `num`
FROM `ApplicationInfo`;
CREATE TABLE `ApplicationStatus_1` (
  `status` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `message` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `event_time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `__pk_hash` CHAR(32) CHARACTER SET `UTF-16LE`,
  PRIMARY KEY (`__pk_hash`) NOT ENFORCED
)
PARTITIONED BY (`customer_id`)
WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = 'ApplicationStatus'
);
CREATE TABLE `_Applications_2` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`) NOT ENFORCED
)
PARTITIONED BY (`loan_type_id`)
WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = '_Applications'
);
CREATE TABLE `_LoanTypes_3` (
  `id` BIGINT NOT NULL,
  `name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `description` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `interest_rate` DOUBLE NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `max_duration` BIGINT NOT NULL,
  `min_duration` BIGINT NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`) NOT ENFORCED
) WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = '_LoanTypes'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`ApplicationStatus_1`
(SELECT `status`, `message`, `event_time`, `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `max_amount`, `min_amount`, `hash_columns`(`status`, `message`, `event_time`, `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `max_amount`, `min_amount`) AS `__pk_hash`
 FROM `default_catalog`.`default_database`.`ApplicationStatus`)
;
INSERT INTO `default_catalog`.`default_database`.`_Applications_2`
 (SELECT *
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`)
 ;
 INSERT INTO `default_catalog`.`default_database`.`_LoanTypes_3`
  (SELECT *
   FROM `default_catalog`.`default_database`.`_LoanTypesStream`)
  ;
  END
>>>iceberg-duckdb-schema.sql
CREATE TABLE IF NOT EXISTS "ApplicationStatus" ("status" TEXT NOT NULL, "message" TEXT NOT NULL, "event_time" TIMESTAMP WITH TIME ZONE NOT NULL, "id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "__pk_hash" TEXT  , PRIMARY KEY ("__pk_hash"));
CREATE TABLE IF NOT EXISTS "_Applications" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"));
CREATE TABLE IF NOT EXISTS "_LoanTypes" ("id" BIGINT NOT NULL, "name" TEXT NOT NULL, "description" TEXT NOT NULL, "interest_rate" DOUBLE PRECISION NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "max_duration" BIGINT NOT NULL, "min_duration" BIGINT NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"))
>>>iceberg-duckdb-views.sql

>>>iceberg-schema.sql
CREATE TABLE IF NOT EXISTS "ApplicationStatus" ("status" TEXT NOT NULL, "message" TEXT NOT NULL, "event_time" TIMESTAMP WITH TIME ZONE NOT NULL, "id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "__pk_hash" TEXT  , PRIMARY KEY ("__pk_hash"));
CREATE TABLE IF NOT EXISTS "_Applications" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"));
CREATE TABLE IF NOT EXISTS "_LoanTypes" ("id" BIGINT NOT NULL, "name" TEXT NOT NULL, "description" TEXT NOT NULL, "interest_rate" DOUBLE PRECISION NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "max_duration" BIGINT NOT NULL, "min_duration" BIGINT NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"))
>>>iceberg-views.sql

>>>vertx.json
{
  "model" : {
    "queries" : [
      {
        "type" : "args",
        "parentType" : "Query",
        "fieldName" : "ApplicationInfo",
        "exec" : {
          "arguments" : [
            {
              "type" : "variable",
              "path" : "offset"
            },
            {
              "type" : "variable",
              "path" : "limit"
            }
          ],
          "query" : {
            "type" : "SqlQuery",
            "sql" : "SELECT \"t\".\"id\", \"t\".\"customer_id\", \"t\".\"loan_type_id\", \"t\".\"amount\", \"t\".\"duration\", \"t\".\"application_date\", \"t\".\"updated_at\", \"t0\".\"id\" AS \"id0\", \"t0\".\"name\", \"t0\".\"description\", \"t0\".\"interest_rate\", \"t0\".\"max_amount\", \"t0\".\"min_amount\", \"t0\".\"max_duration\", \"t0\".\"min_duration\", \"t0\".\"updated_at\" AS \"updated_at0\", \"t1\".\"id\" AS \"id2\"\nFROM (SELECT *\n  FROM \"iceberg_scan\"('/tmp/duckdb/default_database/_Applications', ALLOW_MOVED_PATHS = TRUE)) AS \"t\"\n INNER JOIN (SELECT *\n  FROM \"iceberg_scan\"('/tmp/duckdb/default_database/_LoanTypes', ALLOW_MOVED_PATHS = TRUE)) AS \"t0\" ON \"t\".\"loan_type_id\" = \"t0\".\"id\"\n LEFT JOIN (SELECT *\n  FROM \"iceberg_scan\"('/tmp/duckdb/default_database/_LoanTypes', ALLOW_MOVED_PATHS = TRUE)) AS \"t1\" ON \"t\".\"customer_id\" = \"t1\".\"id\"",
            "parameters" : [ ],
            "pagination" : "LIMIT_AND_OFFSET",
            "database" : "DUCKDB"
          }
        }
      },
      {
        "type" : "args",
        "parentType" : "Query",
        "fieldName" : "ApplicationStatus",
        "exec" : {
          "arguments" : [
            {
              "type" : "variable",
              "path" : "offset"
            },
            {
              "type" : "variable",
              "path" : "limit"
            }
          ],
          "query" : {
            "type" : "SqlQuery",
            "sql" : "SELECT \"status\", \"message\", \"event_time\", \"id\", \"customer_id\", \"loan_type_id\", \"amount\", \"duration\", \"max_amount\", \"min_amount\"\nFROM \"iceberg_scan\"('/tmp/duckdb/default_database/ApplicationStatus', ALLOW_MOVED_PATHS = TRUE)",
            "parameters" : [ ],
            "pagination" : "LIMIT_AND_OFFSET",
            "database" : "DUCKDB"
          }
        }
      }
    ],
    "mutations" : [ ],
    "subscriptions" : [ ],
    "schema" : {
      "type" : "string",
      "schema" : "type ApplicationInfo {\n  id: GraphQLBigInteger!\n  customer_id: GraphQLBigInteger!\n  loan_type_id: GraphQLBigInteger!\n  amount: Float!\n  duration: GraphQLBigInteger!\n  application_date: DateTime!\n  updated_at: DateTime!\n  id0: GraphQLBigInteger!\n  name: String!\n  description: String!\n  interest_rate: Float!\n  max_amount: Float!\n  min_amount: Float!\n  max_duration: GraphQLBigInteger!\n  min_duration: GraphQLBigInteger!\n  updated_at0: DateTime!\n  id2: GraphQLBigInteger\n}\n\ntype ApplicationStatus {\n  status: String!\n  message: String!\n  event_time: DateTime!\n  id: GraphQLBigInteger!\n  customer_id: GraphQLBigInteger!\n  loan_type_id: GraphQLBigInteger!\n  amount: Float!\n  duration: GraphQLBigInteger!\n  max_amount: Float!\n  min_amount: Float!\n}\n\n\"A slightly refined version of RFC-3339 compliant DateTime Scalar\"\nscalar DateTime\n\n\"An arbitrary precision signed integer\"\nscalar GraphQLBigInteger\n\ntype Query {\n  ApplicationInfo(limit: Int = 10, offset: Int = 0): [ApplicationInfo!]\n  ApplicationStatus(limit: Int = 10, offset: Int = 0): [ApplicationStatus!]\n}\n"
    }
  }
}
