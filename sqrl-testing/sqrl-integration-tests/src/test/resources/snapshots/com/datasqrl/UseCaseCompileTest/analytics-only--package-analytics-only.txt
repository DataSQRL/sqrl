>>>pipeline_explain.txt
=== ApplicationInfo
ID:     default_catalog.default_database.ApplicationInfo
Type:   state
Stage:  iceberg
Inputs: default_catalog.default_database._Applications, default_catalog.default_database._LoanTypes
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id0: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at0: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id2: BIGINT
Plan:
LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6], id0=[$7], name=[$8], description=[$9], interest_rate=[$10], max_amount=[$11], min_amount=[$12], max_duration=[$13], min_duration=[$14], updated_at0=[$15], id2=[$16])
  LogicalJoin(condition=[=($16, $1)], joinType=[left])
    LogicalJoin(condition=[=($7, $2)], joinType=[inner])
      LogicalTableScan(table=[[default_catalog, default_database, _Applications]])
      LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
    LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
SQL: CREATE VIEW ApplicationInfo AS  SELECT a.*, t.*, t2.id AS id2 FROM _Applications a
    JOIN _LoanTypes t ON t.id = a.loan_type_id
    LEFT JOIN _LoanTypes t2 ON t2.id = a.customer_id;

=== ApplicationStatus
ID:     default_catalog.default_database.ApplicationStatus
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationUpdates, default_catalog.default_database._Applications, default_catalog.default_database._LoanTypes
Annotations:
 - stream-root: _ApplicationUpdates__def
Primary Key: -
Timestamp  : event_time
Schema:
 - status: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - message: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - event_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
Plan:
LogicalProject(status=[$1], message=[$2], event_time=[$3], id=[$4], customer_id=[$5], loan_type_id=[$6], amount=[$7], duration=[$8], max_amount=[$15], min_amount=[$16])
  LogicalCorrelate(correlation=[$cor3], joinType=[inner], requiredColumns=[{3, 6}])
    LogicalCorrelate(correlation=[$cor2], joinType=[inner], requiredColumns=[{0, 3}])
      LogicalTableScan(table=[[default_catalog, default_database, _ApplicationUpdates]])
      LogicalFilter(condition=[=($0, $cor2.loan_application_id)])
        LogicalSnapshot(period=[$cor2.event_time])
          LogicalTableScan(table=[[default_catalog, default_database, _Applications]])
    LogicalFilter(condition=[=($0, $cor3.loan_type_id)])
      LogicalSnapshot(period=[$cor3.event_time])
        LogicalTableScan(table=[[default_catalog, default_database, _LoanTypes]])
SQL: CREATE VIEW ApplicationStatus AS  SELECT u.status, u.message, u.event_time, a.id, a.customer_id, a.loan_type_id,
                            a.amount, a.duration, t.max_amount, t.min_amount
                     FROM _ApplicationUpdates u JOIN _Applications FOR SYSTEM_TIME AS OF u.`event_time` a ON a.id = u.loan_application_id
                                               JOIN _LoanTypes FOR SYSTEM_TIME AS OF u.`event_time` t ON t.id = a.loan_type_id;

=== _ApplicationUpdates
ID:     default_catalog.default_database._ApplicationUpdates
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationUpdates__def
Annotations:
 - stream-root: _ApplicationUpdates__def
Primary Key: loan_application_id, event_time
Timestamp  : event_time
Schema:
 - loan_application_id: BIGINT NOT NULL
 - status: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - message: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - event_time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(loan_application_id=[$0], status=[$1], message=[$2], event_time=[$3])
  LogicalWatermarkAssigner(rowtime=[event_time], watermark=[$3])
    LogicalTableScan(table=[[default_catalog, default_database, _ApplicationUpdates__def]])
SQL: CREATE VIEW `_ApplicationUpdates`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_ApplicationUpdates__def`
=== _Applications
ID:     default_catalog.default_database._Applications
Type:   state
Stage:  flink
Inputs: default_catalog.default_database._ApplicationsStream
Annotations:
 - mostRecentDistinct: true
 - stream-root: _ApplicationsStream__def
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6])
  LogicalFilter(condition=[=($7, 1)])
    LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $6 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, _ApplicationsStream]])
SQL: CREATE VIEW `_Applications`
AS
SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`
FROM (SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== _ApplicationsStream
ID:     default_catalog.default_database._ApplicationsStream
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._ApplicationsStream__def
Annotations:
 - stream-root: _ApplicationsStream__def
Primary Key: id, updated_at
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - customer_id: BIGINT NOT NULL
 - loan_type_id: BIGINT NOT NULL
 - amount: DOUBLE NOT NULL
 - duration: BIGINT NOT NULL
 - application_date: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], customer_id=[$1], loan_type_id=[$2], amount=[$3], duration=[$4], application_date=[$5], updated_at=[$6])
  LogicalWatermarkAssigner(rowtime=[updated_at], watermark=[-($6, 1:INTERVAL SECOND)])
    LogicalTableScan(table=[[default_catalog, default_database, _ApplicationsStream__def]])
SQL: CREATE VIEW `_ApplicationsStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_ApplicationsStream__def`
=== _LoanTypes
ID:     default_catalog.default_database._LoanTypes
Type:   state
Stage:  flink
Inputs: default_catalog.default_database._LoanTypesStream
Annotations:
 - mostRecentDistinct: true
 - stream-root: _LoanTypesStream__def
Primary Key: id
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], name=[$1], description=[$2], interest_rate=[$3], max_amount=[$4], min_amount=[$5], max_duration=[$6], min_duration=[$7], updated_at=[$8])
  LogicalFilter(condition=[=($9, 1)])
    LogicalProject(id=[$0], name=[$1], description=[$2], interest_rate=[$3], max_amount=[$4], min_amount=[$5], max_duration=[$6], min_duration=[$7], updated_at=[$8], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $8 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, _LoanTypesStream]])
SQL: CREATE VIEW `_LoanTypes`
AS
SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`
FROM (SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_LoanTypesStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== _LoanTypesStream
ID:     default_catalog.default_database._LoanTypesStream
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._LoanTypesStream__def
Annotations:
 - stream-root: _LoanTypesStream__def
Primary Key: id, updated_at
Timestamp  : updated_at
Schema:
 - id: BIGINT NOT NULL
 - name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - description: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - interest_rate: DOUBLE NOT NULL
 - max_amount: DOUBLE NOT NULL
 - min_amount: DOUBLE NOT NULL
 - max_duration: BIGINT NOT NULL
 - min_duration: BIGINT NOT NULL
 - updated_at: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], name=[$1], description=[$2], interest_rate=[$3], max_amount=[$4], min_amount=[$5], max_duration=[$6], min_duration=[$7], updated_at=[$8])
  LogicalWatermarkAssigner(rowtime=[updated_at], watermark=[-($8, 1:INTERVAL SECOND)])
    LogicalTableScan(table=[[default_catalog, default_database, _LoanTypesStream__def]])
SQL: CREATE VIEW `_LoanTypesStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_LoanTypesStream__def`
>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `_ApplicationsStream__schema` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_ApplicationsStream__def` (
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED,
  WATERMARK FOR `updated_at` AS `updated_at` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/applications.jsonl',
  'source.monitor-interval' = '10 sec',
  'connector' = 'filesystem'
)
LIKE `_ApplicationsStream__schema`;
CREATE VIEW `_ApplicationsStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_ApplicationsStream__def`;
CREATE TEMPORARY TABLE `_LoanTypesStream__schema` (
  `id` BIGINT NOT NULL,
  `name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `description` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `interest_rate` DOUBLE NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `max_duration` BIGINT NOT NULL,
  `min_duration` BIGINT NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_LoanTypesStream__def` (
  PRIMARY KEY (`id`, `updated_at`) NOT ENFORCED,
  WATERMARK FOR `updated_at` AS `updated_at` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/loan_types.jsonl',
  'source.monitor-interval' = '10 sec',
  'connector' = 'filesystem'
)
LIKE `_LoanTypesStream__schema`;
CREATE VIEW `_LoanTypesStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_LoanTypesStream__def`;
CREATE TEMPORARY TABLE `_ApplicationUpdates__schema` (
  `loan_application_id` BIGINT NOT NULL,
  `status` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `message` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `event_time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `_ApplicationUpdates__def` (
  PRIMARY KEY (`loan_application_id`, `event_time`) NOT ENFORCED,
  WATERMARK FOR `event_time` AS `event_time`
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/application_updates.jsonl',
  'connector' = 'filesystem'
)
LIKE `_ApplicationUpdates__schema`;
CREATE VIEW `_ApplicationUpdates`
AS
SELECT *
FROM `default_catalog`.`default_database`.`_ApplicationUpdates__def`;
CREATE VIEW `_Applications`
AS
SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`
FROM (SELECT `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `application_date`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `_LoanTypes`
AS
SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`
FROM (SELECT `id`, `name`, `description`, `interest_rate`, `max_amount`, `min_amount`, `max_duration`, `min_duration`, `updated_at`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated_at` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`_LoanTypesStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `ApplicationStatus`
AS
SELECT `u`.`status`, `u`.`message`, `u`.`event_time`, `a`.`id`, `a`.`customer_id`, `a`.`loan_type_id`, `a`.`amount`, `a`.`duration`, `t`.`max_amount`, `t`.`min_amount`
FROM `_ApplicationUpdates` AS `u`
 INNER JOIN `_Applications` FOR SYSTEM_TIME AS OF `u`.`event_time` AS `a` ON `a`.`id` = `u`.`loan_application_id`
 INNER JOIN `_LoanTypes` FOR SYSTEM_TIME AS OF `u`.`event_time` AS `t` ON `t`.`id` = `a`.`loan_type_id`;
CREATE VIEW `ApplicationInfo`
AS
SELECT `a`.*, `t`.*, `t2`.`id` AS `id2`
FROM `_Applications` AS `a`
 INNER JOIN `_LoanTypes` AS `t` ON `t`.`id` = `a`.`loan_type_id`
 LEFT JOIN `_LoanTypes` AS `t2` ON `t2`.`id` = `a`.`customer_id`;
CREATE VIEW `ApplicationInfoTest`
AS
SELECT COUNT(1) AS `num`
FROM `ApplicationInfo`;
CREATE TABLE `ApplicationStatus_1` (
  `status` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `message` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `event_time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `__pk_hash` CHAR(32) CHARACTER SET `UTF-16LE`,
  PRIMARY KEY (`__pk_hash`) NOT ENFORCED
)
PARTITIONED BY (`customer_id`)
WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = 'ApplicationStatus_1'
);
CREATE TABLE `_Applications_2` (
  `id` BIGINT NOT NULL,
  `customer_id` BIGINT NOT NULL,
  `loan_type_id` BIGINT NOT NULL,
  `amount` DOUBLE NOT NULL,
  `duration` BIGINT NOT NULL,
  `application_date` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`) NOT ENFORCED
)
PARTITIONED BY (`loan_type_id`)
WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = '_Applications_2'
);
CREATE TABLE `_LoanTypes_3` (
  `id` BIGINT NOT NULL,
  `name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `description` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `interest_rate` DOUBLE NOT NULL,
  `max_amount` DOUBLE NOT NULL,
  `min_amount` DOUBLE NOT NULL,
  `max_duration` BIGINT NOT NULL,
  `min_duration` BIGINT NOT NULL,
  `updated_at` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  PRIMARY KEY (`id`) NOT ENFORCED
) WITH (
  'write.parquet.page-size-bytes' = '1000',
  'warehouse' = '/tmp/duckdb',
  'catalog-type' = 'hadoop',
  'catalog-name' = 'mydatabase',
  'connector' = 'iceberg',
  'catalog-table' = '_LoanTypes_3'
);
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`ApplicationStatus_1`
(SELECT `status`, `message`, `event_time`, `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `max_amount`, `min_amount`, HASHCOLUMNS(`status`, `message`, `event_time`, `id`, `customer_id`, `loan_type_id`, `amount`, `duration`, `max_amount`, `min_amount`) AS `__pk_hash`
 FROM `default_catalog`.`default_database`.`ApplicationStatus`)
;
INSERT INTO `default_catalog`.`default_database`.`_Applications_2`
 (SELECT *
  FROM `default_catalog`.`default_database`.`_ApplicationsStream`)
 ;
 INSERT INTO `default_catalog`.`default_database`.`_LoanTypes_3`
  (SELECT *
   FROM `default_catalog`.`default_database`.`_LoanTypesStream`)
  ;
  END
>>>iceberg-duckdb-schema.sql
CREATE TABLE IF NOT EXISTS "ApplicationStatus_1" ("status" TEXT NOT NULL, "message" TEXT NOT NULL, "event_time" TIMESTAMP WITH TIME ZONE NOT NULL, "id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "__pk_hash" TEXT  , PRIMARY KEY ("__pk_hash"));
CREATE TABLE IF NOT EXISTS "_Applications_2" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"));
CREATE TABLE IF NOT EXISTS "_LoanTypes_3" ("id" BIGINT NOT NULL, "name" TEXT NOT NULL, "description" TEXT NOT NULL, "interest_rate" DOUBLE PRECISION NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "max_duration" BIGINT NOT NULL, "min_duration" BIGINT NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"))
>>>iceberg-duckdb-views.sql

>>>iceberg-schema.sql
CREATE TABLE IF NOT EXISTS "ApplicationStatus_1" ("status" TEXT NOT NULL, "message" TEXT NOT NULL, "event_time" TIMESTAMP WITH TIME ZONE NOT NULL, "id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "__pk_hash" TEXT  , PRIMARY KEY ("__pk_hash"));
CREATE TABLE IF NOT EXISTS "_Applications_2" ("id" BIGINT NOT NULL, "customer_id" BIGINT NOT NULL, "loan_type_id" BIGINT NOT NULL, "amount" DOUBLE PRECISION NOT NULL, "duration" BIGINT NOT NULL, "application_date" TIMESTAMP WITH TIME ZONE NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"));
CREATE TABLE IF NOT EXISTS "_LoanTypes_3" ("id" BIGINT NOT NULL, "name" TEXT NOT NULL, "description" TEXT NOT NULL, "interest_rate" DOUBLE PRECISION NOT NULL, "max_amount" DOUBLE PRECISION NOT NULL, "min_amount" DOUBLE PRECISION NOT NULL, "max_duration" BIGINT NOT NULL, "min_duration" BIGINT NOT NULL, "updated_at" TIMESTAMP WITH TIME ZONE NOT NULL , PRIMARY KEY ("id"))
>>>iceberg-views.sql

>>>vertx.json
{ }
