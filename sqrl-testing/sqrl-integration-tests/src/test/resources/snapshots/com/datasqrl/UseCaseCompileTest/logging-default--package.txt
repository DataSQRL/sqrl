>>>pipeline_explain.txt
=== Data
ID:     data_2
Type:   stream
Stage:  flink
Primary Key: id
Timestamp  : timestamp
Schema:
 - id: BIGINT NOT NULL
 - epoch_timestamp: BIGINT NOT NULL
 - some_value: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - timestamp: TIMESTAMP_WITH_LOCAL_TIME_ZONE(3) NOT NULL
Plan:
LogicalTableScan(table=[[data_1]])

=== logger.LogData
ID:     data_2_1
Type:   export
Stage:  flink
Inputs: data_2

>>>flink.json
{
  "flinkSql" : [
    "CREATE TEMPORARY FUNCTION IF NOT EXISTS `epochmillitotimestamp` AS 'com.datasqrl.time.EpochMilliToTimestamp' LANGUAGE JAVA;",
    "CREATE TEMPORARY TABLE `data_1` (\n  `id` BIGINT NOT NULL,\n  `epoch_timestamp` BIGINT NOT NULL,\n  `some_value` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,\n  `timestamp` AS EPOCHMILLITOTIMESTAMP(`epoch_timestamp`),\n  PRIMARY KEY (`id`) NOT ENFORCED,\n  WATERMARK FOR `timestamp` AS `timestamp` - INTERVAL '0.001' SECOND\n) WITH (\n  'fields.id.end' = '9',\n  'fields.epoch_timestamp.kind' = 'sequence',\n  'number-of-rows' = '10',\n  'connector' = 'datagen',\n  'fields.epoch_timestamp.end' = '1719319565',\n  'fields.some_value.kind' = 'random',\n  'fields.id.kind' = 'sequence',\n  'fields.id.start' = '0',\n  'fields.epoch_timestamp.start' = '1719318565'\n);",
    "CREATE TEMPORARY TABLE `data_2_1` (\n  `id` BIGINT NOT NULL,\n  `epoch_timestamp` BIGINT NOT NULL,\n  `some_value` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,\n  `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL\n) WITH (\n  'connector' = 'print',\n  'print-identifier' = 'LogData'\n);",
    "CREATE VIEW `table$1`\nAS\nSELECT *\nFROM `data_1`;",
    "EXECUTE STATEMENT SET BEGIN\nINSERT INTO `data_2_1`\n(SELECT *\n FROM `table$1`)\n;\nEND;"
  ],
  "connectors" : [
    "print",
    "datagen"
  ],
  "formats" : [ ],
  "compliedPlan" : "{\n  \"flinkVersion\" : \"1.19\",\n  \"nodes\" : [ {\n    \"id\" : 163,\n    \"type\" : \"stream-exec-table-source-scan_1\",\n    \"scanTableSource\" : {\n      \"table\" : {\n        \"identifier\" : \"`default_catalog`.`default_database`.`data_1`\"\n      }\n    },\n    \"outputType\" : \"ROW<`id` BIGINT NOT NULL, `epoch_timestamp` BIGINT NOT NULL, `some_value` VARCHAR(2147483647) NOT NULL, `timestamp` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL>\",\n    \"description\" : \"TableSourceScan(table=[[default_catalog, default_database, data_1]], fields=[id, epoch_timestamp, some_value, timestamp])\",\n    \"inputProperties\" : [ ]\n  }, {\n    \"id\" : 164,\n    \"type\" : \"stream-exec-watermark-assigner_1\",\n    \"watermarkExpr\" : {\n      \"kind\" : \"CALL\",\n      \"syntax\" : \"BINARY\",\n      \"internalName\" : \"$-$1\",\n      \"operands\" : [ {\n        \"kind\" : \"INPUT_REF\",\n        \"inputIndex\" : 3,\n        \"type\" : \"TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL\"\n      }, {\n        \"kind\" : \"LITERAL\",\n        \"value\" : \"1\",\n        \"type\" : \"INTERVAL SECOND(6) NOT NULL\"\n      } ],\n      \"type\" : \"TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL\"\n    },\n    \"rowtimeFieldIndex\" : 3,\n    \"inputProperties\" : [ {\n      \"requiredDistribution\" : {\n        \"type\" : \"UNKNOWN\"\n      },\n      \"damBehavior\" : \"PIPELINED\",\n      \"priority\" : 0\n    } ],\n    \"outputType\" : {\n      \"type\" : \"ROW\",\n      \"fields\" : [ {\n        \"name\" : \"id\",\n        \"fieldType\" : \"BIGINT NOT NULL\"\n      }, {\n        \"name\" : \"epoch_timestamp\",\n        \"fieldType\" : \"BIGINT NOT NULL\"\n      }, {\n        \"name\" : \"some_value\",\n        \"fieldType\" : \"VARCHAR(2147483647) NOT NULL\"\n      }, {\n        \"name\" : \"timestamp\",\n        \"fieldType\" : {\n          \"type\" : \"TIMESTAMP_WITH_LOCAL_TIME_ZONE\",\n          \"nullable\" : false,\n          \"precision\" : 3,\n          \"kind\" : \"ROWTIME\"\n        }\n      } ]\n    },\n    \"description\" : \"WatermarkAssigner(rowtime=[timestamp], watermark=[(timestamp - 1:INTERVAL SECOND)])\"\n  }, {\n    \"id\" : 165,\n    \"type\" : \"stream-exec-sink_1\",\n    \"configuration\" : {\n      \"table.exec.sink.keyed-shuffle\" : \"AUTO\",\n      \"table.exec.sink.not-null-enforcer\" : \"ERROR\",\n      \"table.exec.sink.rowtime-inserter\" : \"ENABLED\",\n      \"table.exec.sink.type-length-enforcer\" : \"IGNORE\",\n      \"table.exec.sink.upsert-materialize\" : \"AUTO\"\n    },\n    \"dynamicTableSink\" : {\n      \"table\" : {\n        \"identifier\" : \"`default_catalog`.`default_database`.`data_2_1`\"\n      }\n    },\n    \"inputChangelogMode\" : [ \"INSERT\" ],\n    \"inputUpsertKey\" : [ 0 ],\n    \"inputProperties\" : [ {\n      \"requiredDistribution\" : {\n        \"type\" : \"UNKNOWN\"\n      },\n      \"damBehavior\" : \"PIPELINED\",\n      \"priority\" : 0\n    } ],\n    \"outputType\" : {\n      \"type\" : \"ROW\",\n      \"fields\" : [ {\n        \"name\" : \"id\",\n        \"fieldType\" : \"BIGINT NOT NULL\"\n      }, {\n        \"name\" : \"epoch_timestamp\",\n        \"fieldType\" : \"BIGINT NOT NULL\"\n      }, {\n        \"name\" : \"some_value\",\n        \"fieldType\" : \"VARCHAR(2147483647) NOT NULL\"\n      }, {\n        \"name\" : \"timestamp\",\n        \"fieldType\" : {\n          \"type\" : \"TIMESTAMP_WITH_LOCAL_TIME_ZONE\",\n          \"nullable\" : false,\n          \"precision\" : 3,\n          \"kind\" : \"ROWTIME\"\n        }\n      } ]\n    },\n    \"description\" : \"Sink(table=[default_catalog.default_database.data_2_1], fields=[id, epoch_timestamp, some_value, timestamp])\"\n  } ],\n  \"edges\" : [ {\n    \"source\" : 163,\n    \"target\" : 164,\n    \"shuffle\" : {\n      \"type\" : \"FORWARD\"\n    },\n    \"shuffleMode\" : \"PIPELINED\"\n  }, {\n    \"source\" : 164,\n    \"target\" : 165,\n    \"shuffle\" : {\n      \"type\" : \"FORWARD\"\n    },\n    \"shuffleMode\" : \"PIPELINED\"\n  } ]\n}"
}
>>>kafka.json
{
  "topics" : [ ]
}
