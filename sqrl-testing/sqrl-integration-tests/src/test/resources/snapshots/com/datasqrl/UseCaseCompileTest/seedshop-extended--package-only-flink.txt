>>>pipeline_explain.txt
=== CustomerPromotion
ID:     default_catalog.default_database.CustomerPromotion
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Customers, default_catalog.default_database.CustomersSpending
Annotations:
 - stream-root: Orders__def
Primary Key: -
Timestamp  : -
Schema:
 - customerid: BIGINT NOT NULL
 - first_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - last_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - email: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - spend: DOUBLE NOT NULL
 - saved: DOUBLE NOT NULL
Plan:
LogicalProject(customerid=[$0], first_name=[$5], last_name=[$6], email=[$7], spend=[$2], saved=[$3])
  LogicalFilter(condition=[>($2, 250)])
    LogicalCorrelate(correlation=[$cor19], joinType=[inner], requiredColumns=[{0, 1}])
      LogicalTableScan(table=[[default_catalog, default_database, CustomersSpending]])
      LogicalFilter(condition=[=($cor19.customerid, $0)])
        LogicalSnapshot(period=[$cor19.week])
          LogicalTableScan(table=[[default_catalog, default_database, Customers]])
SQL: CREATE VIEW CustomerPromotion AS  SELECT s.customerid, c.first_name, c.last_name, c.email, s.spend, s.saved
        FROM CustomersSpending s JOIN Customers FOR SYSTEM_TIME AS OF `week` c ON s.customerid = c.id
        WHERE s.spend > 250;

=== Customers
ID:     default_catalog.default_database.Customers
Type:   state
Stage:  flink
Inputs: default_catalog.default_database.CustomersStream
Annotations:
 - mostRecentDistinct: true
 - stream-root: CustomersStream__def
Primary Key: id
Timestamp  : timestamp
Schema:
 - id: BIGINT NOT NULL
 - first_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - last_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - email: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - ip_address: VARCHAR(2147483647) CHARACTER SET "UTF-16LE"
 - country: VARCHAR(2147483647) CHARACTER SET "UTF-16LE"
 - changed_on: BIGINT NOT NULL
 - timestamp: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], first_name=[$1], last_name=[$2], email=[$3], ip_address=[$4], country=[$5], changed_on=[$6], timestamp=[$7])
  LogicalFilter(condition=[=($8, 1)])
    LogicalProject(id=[$0], first_name=[$1], last_name=[$2], email=[$3], ip_address=[$4], country=[$5], changed_on=[$6], timestamp=[$7], __sqrlinternal_rownum=[ROW_NUMBER() OVER (PARTITION BY $0 ORDER BY $7 DESC NULLS LAST)])
      LogicalTableScan(table=[[default_catalog, default_database, CustomersStream]])
SQL: CREATE VIEW `Customers`
AS
SELECT `id`, `first_name`, `last_name`, `email`, `ip_address`, `country`, `changed_on`, `timestamp`
FROM (SELECT `id`, `first_name`, `last_name`, `email`, `ip_address`, `country`, `changed_on`, `timestamp`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `timestamp` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`CustomersStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1
=== CustomersSpending
ID:     default_catalog.default_database.CustomersSpending
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.OrdersTotals
Annotations:
 - features: STREAM_WINDOW_AGGREGATION (feature)
 - stream-root: Orders__def
 - sort: [1 DESC-nulls-last]
Primary Key: -
Timestamp  : week
Schema:
 - customerid: BIGINT NOT NULL
 - week: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - spend: DOUBLE NOT NULL
 - saved: DOUBLE NOT NULL
Plan:
LogicalProject(customerid=[$0], week=[$3], spend=[$4], saved=[$5])
  LogicalAggregate(group=[{0, 1, 2, 3}], spend=[SUM($4)], saved=[SUM($5)])
    LogicalProject(customerid=[$2], window_start=[$5], window_end=[$6], week=[$7], price=[$3], saving=[$4])
      LogicalTableFunctionScan(invocation=[TUMBLE(DESCRIPTOR($1), 604800000:INTERVAL DAY)], rowType=[RecordType(BIGINT id, TIMESTAMP_LTZ(3) *ROWTIME* time, BIGINT customerid, DOUBLE price, DOUBLE saving, TIMESTAMP(3) window_start, TIMESTAMP(3) window_end, TIMESTAMP_LTZ(3) *ROWTIME* window_time)])
        LogicalProject(id=[$0], time=[$1], customerid=[$2], price=[$3], saving=[$4])
          LogicalTableScan(table=[[default_catalog, default_database, OrdersTotals]])
SQL: CREATE VIEW CustomersSpending AS  SELECT customerid, window_time AS week,
         sum(price) AS spend, sum(saving) AS saved
      FROM TABLE(TUMBLE(TABLE OrdersTotals, DESCRIPTOR(`time`), INTERVAL '7' DAYS))
      GROUP BY customerid, window_start, window_end, window_time
      ORDER BY week DESC;

=== CustomersStream
ID:     default_catalog.default_database.CustomersStream
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.CustomersStream__def
Annotations:
 - stream-root: CustomersStream__def
Primary Key: id, changed_on
Timestamp  : timestamp
Schema:
 - id: BIGINT NOT NULL
 - first_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - last_name: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - email: VARCHAR(2147483647) CHARACTER SET "UTF-16LE" NOT NULL
 - ip_address: VARCHAR(2147483647) CHARACTER SET "UTF-16LE"
 - country: VARCHAR(2147483647) CHARACTER SET "UTF-16LE"
 - changed_on: BIGINT NOT NULL
 - timestamp: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
Plan:
LogicalProject(id=[$0], first_name=[$1], last_name=[$2], email=[$3], ip_address=[$4], country=[$5], changed_on=[$6], timestamp=[$7])
  LogicalWatermarkAssigner(rowtime=[timestamp], watermark=[-($7, 1:INTERVAL SECOND)])
    LogicalProject(id=[$0], first_name=[$1], last_name=[$2], email=[$3], ip_address=[$4], country=[$5], changed_on=[$6], timestamp=[EPOCHMILLITOTIMESTAMP($6)])
      LogicalTableScan(table=[[default_catalog, default_database, CustomersStream__def]])
SQL: CREATE VIEW `CustomersStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`CustomersStream__def`
=== Orders
ID:     default_catalog.default_database.Orders
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Orders__def
Annotations:
 - features: DENORMALIZE (feature)
 - stream-root: Orders__def
Primary Key: id, time
Timestamp  : time
Schema:
 - id: BIGINT NOT NULL
 - customerid: BIGINT NOT NULL
 - time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - items: RecordType:peek_no_expand(BIGINT NOT NULL productid, BIGINT NOT NULL quantity, DOUBLE NOT NULL unit_price, DOUBLE discount) NOT NULL ARRAY NOT NULL
Plan:
LogicalProject(id=[$0], customerid=[$1], time=[$2], items=[$3])
  LogicalWatermarkAssigner(rowtime=[time], watermark=[-($2, 1:INTERVAL SECOND)])
    LogicalTableScan(table=[[default_catalog, default_database, Orders__def]])
SQL: CREATE VIEW `Orders`
AS
SELECT *
FROM `default_catalog`.`default_database`.`Orders__def`
=== OrdersTotals
ID:     default_catalog.default_database.OrdersTotals
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database._OrderItems
Annotations:
 - features: STREAM_WINDOW_AGGREGATION (feature)
 - stream-root: Orders__def
Primary Key: -
Timestamp  : time
Schema:
 - id: BIGINT NOT NULL
 - time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - customerid: BIGINT NOT NULL
 - price: DOUBLE NOT NULL
 - saving: DOUBLE NOT NULL
Plan:
LogicalProject(id=[$0], time=[$4], customerid=[$1], price=[$5], saving=[$6])
  LogicalAggregate(group=[{0, 1, 2, 3, 4}], price=[SUM($5)], saving=[SUM($6)])
    LogicalProject(id=[$0], customerid=[$2], window_start=[$7], window_end=[$8], time=[$9], $f5=[-(*($4, $5), coalesce($6, 0.0:DOUBLE))], $f6=[coalesce($6, 0.0:DOUBLE)])
      LogicalTableFunctionScan(invocation=[TUMBLE(DESCRIPTOR($1), 1:INTERVAL SECOND)], rowType=[RecordType(BIGINT id, TIMESTAMP_LTZ(3) *ROWTIME* time, BIGINT customerid, BIGINT productid, BIGINT quantity, DOUBLE unit_price, DOUBLE discount, TIMESTAMP(3) window_start, TIMESTAMP(3) window_end, TIMESTAMP_LTZ(3) *ROWTIME* window_time)])
        LogicalProject(id=[$0], time=[$1], customerid=[$2], productid=[$3], quantity=[$4], unit_price=[$5], discount=[$6])
          LogicalTableScan(table=[[default_catalog, default_database, _OrderItems]])
SQL: CREATE VIEW OrdersTotals AS  SELECT id, window_time AS `time`, customerid, sum(quantity * unit_price - coalesce(discount, 0.0)) as price,
                  sum(coalesce(discount, 0.0)) as saving
                FROM TABLE(TUMBLE(TABLE _OrderItems, DESCRIPTOR(`time`), INTERVAL '0.001' SECONDS))
                GROUP BY id, customerid, window_start, window_end, window_time;

=== _OrderItems
ID:     default_catalog.default_database._OrderItems
Type:   stream
Stage:  flink
Inputs: default_catalog.default_database.Orders
Annotations:
 - stream-root: Orders__def
Primary Key: -
Timestamp  : time
Schema:
 - id: BIGINT NOT NULL
 - time: TIMESTAMP_LTZ(3) *ROWTIME* NOT NULL
 - customerid: BIGINT NOT NULL
 - productid: BIGINT NOT NULL
 - quantity: BIGINT NOT NULL
 - unit_price: DOUBLE NOT NULL
 - discount: DOUBLE
Plan:
LogicalProject(id=[$0], time=[$2], customerid=[$1], productid=[$4], quantity=[$5], unit_price=[$6], discount=[$7])
  LogicalCorrelate(correlation=[$cor1], joinType=[inner], requiredColumns=[{3}])
    LogicalTableScan(table=[[default_catalog, default_database, Orders]])
    Uncollect
      LogicalProject(items=[$cor1.items])
        LogicalValues(tuples=[[{ 0 }]])
SQL: CREATE VIEW _OrderItems AS  SELECT o.id, o.`time`, o.customerid, i.* FROM Orders o CROSS JOIN UNNEST(o.items) i;

=== promotion
ID:     mySinkPackage.promotion
Type:   export
Stage:  flink
Inputs: default_catalog.default_database.CustomerPromotion

>>>flink-sql-no-functions.sql
CREATE TEMPORARY TABLE `Orders__schema` (
  `id` BIGINT NOT NULL,
  `customerid` BIGINT NOT NULL,
  `time` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL,
  `items` ROW(`productid` BIGINT NOT NULL, `quantity` BIGINT NOT NULL, `unit_price` DOUBLE NOT NULL, `discount` DOUBLE) NOT NULL ARRAY NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `Orders__def` (
  PRIMARY KEY (`id`, `time`) NOT ENFORCED,
  WATERMARK FOR `time` AS `time` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/orderitems.jsonl',
  'connector' = 'filesystem'
)
LIKE `Orders__schema`;
CREATE VIEW `Orders`
AS
SELECT *
FROM `default_catalog`.`default_database`.`Orders__def`;
CREATE TEMPORARY TABLE `ProductsStream__schema` (
  `id` BIGINT NOT NULL,
  `name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `sizing` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `weight_in_gram` BIGINT NOT NULL,
  `type` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `category` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `usda_id` BIGINT NOT NULL,
  `updated` TIMESTAMP(3) WITH LOCAL TIME ZONE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `ProductsStream__def` (
  PRIMARY KEY (`id`, `updated`) NOT ENFORCED,
  WATERMARK FOR `updated` AS `updated` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/products.jsonl',
  'connector' = 'filesystem'
)
LIKE `ProductsStream__schema`;
CREATE VIEW `ProductsStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`ProductsStream__def`;
CREATE TEMPORARY TABLE `CustomersStream__schema` (
  `id` BIGINT NOT NULL,
  `first_name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `last_name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `email` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `ip_address` VARCHAR(2147483647) CHARACTER SET `UTF-16LE`,
  `country` VARCHAR(2147483647) CHARACTER SET `UTF-16LE`,
  `changed_on` BIGINT NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `CustomersStream__def` (
  `timestamp` AS EPOCHMILLITOTIMESTAMP(`changed_on`),
  PRIMARY KEY (`id`, `changed_on`) NOT ENFORCED,
  WATERMARK FOR `timestamp` AS `timestamp` - INTERVAL '0.001' SECOND
) WITH (
  'format' = 'flexible-json',
  'path' = '${DATA_PATH}/customers.jsonl',
  'connector' = 'filesystem'
)
LIKE `CustomersStream__schema`;
CREATE VIEW `CustomersStream`
AS
SELECT *
FROM `default_catalog`.`default_database`.`CustomersStream__def`;
CREATE VIEW `_OrderItems`
AS
SELECT `o`.`id`, `o`.`time`, `o`.`customerid`, `i`.*
FROM `Orders` AS `o`
 CROSS JOIN UNNEST(`o`.`items`) AS `i`;
CREATE VIEW `OrdersTotals`
AS
SELECT `id`, `window_time` AS `time`, `customerid`, SUM(`quantity` * `unit_price` - COALESCE(`discount`, 0.0)) AS `price`, SUM(COALESCE(`discount`, 0.0)) AS `saving`
FROM TABLE(TUMBLE(TABLE `_OrderItems`, DESCRIPTOR(`time`), INTERVAL '0.001' SECOND))
GROUP BY `id`, `customerid`, `window_start`, `window_end`, `window_time`;
CREATE VIEW `Customers`
AS
SELECT `id`, `first_name`, `last_name`, `email`, `ip_address`, `country`, `changed_on`, `timestamp`
FROM (SELECT `id`, `first_name`, `last_name`, `email`, `ip_address`, `country`, `changed_on`, `timestamp`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `timestamp` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`CustomersStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `CustomersSpending`
AS
SELECT `customerid`, `window_time` AS `week`, SUM(`price`) AS `spend`, SUM(`saving`) AS `saved`
FROM TABLE(TUMBLE(TABLE `OrdersTotals`, DESCRIPTOR(`time`), INTERVAL '7' DAY))
GROUP BY `customerid`, `window_start`, `window_end`, `window_time`;
CREATE VIEW `CustomersOrderStats`
AS
SELECT `customerid`, MIN(`time`) AS `first_order`, SUM(`price`) AS `total_spend`, SUM(`saving`) AS `total_saved`, COUNT(1) AS `num_orders`
FROM `OrdersTotals`
GROUP BY `customerid`;
CREATE VIEW `CustomersPastPurchases`
AS
SELECT `o`.`customerid`, `i`.`productid`, COUNT(1) AS `num_orders`, SUM(`i`.`quantity`) AS `total_quantity`
FROM `Orders` AS `o`
 CROSS JOIN UNNEST(`o`.`items`) AS `i`
GROUP BY `o`.`customerid`, `i`.`productid`;
CREATE VIEW `CustomerPurchaseTest`
AS
SELECT `customerid`, `productid`, COUNT(*) AS `num`
FROM `CustomersPastPurchases`
GROUP BY `customerid`, `productid`;
CREATE VIEW `CustomerPromotion`
AS
SELECT `s`.`customerid`, `c`.`first_name`, `c`.`last_name`, `c`.`email`, `s`.`spend`, `s`.`saved`
FROM `CustomersSpending` AS `s`
 INNER JOIN `Customers` FOR SYSTEM_TIME AS OF `week` AS `c` ON `s`.`customerid` = `c`.`id`
WHERE `s`.`spend` > 250;
CREATE TEMPORARY TABLE `promotion_ex1__schema` (
  `customerid` BIGINT NOT NULL,
  `first_name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `last_name` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `email` VARCHAR(2147483647) CHARACTER SET `UTF-16LE` NOT NULL,
  `spend` DOUBLE NOT NULL,
  `saved` DOUBLE NOT NULL
) WITH (
  'connector' = 'datagen'
);
CREATE TABLE `promotion_ex1__def` (
  PRIMARY KEY (`customerid`) NOT ENFORCED
) WITH (
  'format' = 'flexible-json',
  'path' = '/tmp/sink/',
  'connector' = 'filesystem'
)
LIKE `promotion_ex1__schema`;
CREATE VIEW `CustomerPromotionTest`
AS
SELECT COUNT(*) AS `numPromotions`
FROM `CustomerPromotion`;
CREATE VIEW `NumOrders`
AS
SELECT COUNT(*) AS `count`
FROM `Orders`;
CREATE VIEW `Products`
AS
SELECT `id`, `name`, `sizing`, `weight_in_gram`, `type`, `category`, `usda_id`, `updated`
FROM (SELECT `id`, `name`, `sizing`, `weight_in_gram`, `type`, `category`, `usda_id`, `updated`, ROW_NUMBER() OVER (PARTITION BY `id` ORDER BY `updated` DESC NULLS LAST) AS `__sqrlinternal_rownum`
  FROM `default_catalog`.`default_database`.`ProductsStream`) AS `t`
WHERE `__sqrlinternal_rownum` = 1;
CREATE VIEW `ProductsByCountry`
AS
SELECT `p`.`id` AS `productid`, `c`.`country` AS `country`, SUM(`o`.`quantity`) AS `quantity`, SUM(`o`.`quantity` * `o`.`unit_price`) AS `spend`, SUM(`o`.`quantity` * `p`.`weight_in_gram`) AS `weight`
FROM `_OrderItems` AS `o`
 INNER JOIN `Products` FOR SYSTEM_TIME AS OF `o`.`time` AS `p` ON `o`.`productid` = `p`.`id`
 INNER JOIN `Customers` FOR SYSTEM_TIME AS OF `o`.`time` AS `c` ON `o`.`customerid` = `c`.`id`
GROUP BY `p`.`id`, `c`.`country`;
EXECUTE STATEMENT SET BEGIN
INSERT INTO `default_catalog`.`default_database`.`promotion_ex1__def`
(SELECT *
 FROM `default_catalog`.`default_database`.`CustomerPromotion`)
;
END
